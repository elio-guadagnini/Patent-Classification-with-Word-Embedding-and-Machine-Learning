{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_lstm_classify_patents.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QTkyvhPtHC6k",
        "outputId": "e327335d-0dfd-4249-c3b8-6d00c0bc7dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5ZSOUHA_HWNR",
        "outputId": "c4a0c408-1b91-4416-beae-7ee0d2d013ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "!pip install fasttext\n",
        "!pip install q keras==2.2.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.17.5)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (45.1.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.4.3)\n",
            "Requirement already satisfied: q in /usr/local/lib/python3.6/dist-packages (2.6)\n",
            "Requirement already satisfied: keras==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.5) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LbilP2_aGU9r",
        "outputId": "54b3a196-29f5-4250-98a9-5f0e7976c237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "# %tensorflow_version 2.x\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "import _pickle as pickle # object serialization\n",
        "import csv\n",
        "try:\n",
        "    csv.field_size_limit(sys.maxsize)\n",
        "except:\n",
        "    import unicodecsv\n",
        "    import ctypes\n",
        "    unicodecsv.field_size_limit(int(ctypes.c_ulong(-1).value // 2))\n",
        "import re\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.convolutional import MaxPooling1D, Convolution1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import glob\n",
        "import stat\n",
        "\n",
        "from scipy.sparse import lil_matrix\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime\n",
        "from multiprocessing import Queue, Process\n",
        "\n",
        "import gensim\n",
        "\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# from tensorflow.contrib import learn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import coverage_error\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "import collections\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "import fasttext\n",
        "\n",
        "from collections import namedtuple\n",
        "\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "alcIM5xVVw7v",
        "colab": {}
      },
      "source": [
        "# folder helper\n",
        "def get_list_files(path, extension):\n",
        "    if extension:\n",
        "        return glob.glob(path + '*.' + extension)\n",
        "    return glob.glob(path)\n",
        "\n",
        "def create_folder(destination_path):\n",
        "    if not os.path.exists(destination_path):\n",
        "        os.makedirs(destination_path)\n",
        "\n",
        "def link_paths(root_path, ending_path):\n",
        "    return os.path.join(root_path, ending_path)\n",
        "\n",
        "def join_paths(root_path, ending_path):\n",
        "    path = link_paths(root_path, ending_path)\n",
        "    create_folder(path)\n",
        "    return path\n",
        "\n",
        "def get_root_location(ending_path):\n",
        "    return join_paths('/content/drive/My Drive/Colab Notebooks/', ending_path)\n",
        "\n",
        "def ensure_exists_path_location(path):\n",
        "    if os.path.exists(path):\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWwM31UCWRBV",
        "colab": {}
      },
      "source": [
        "# txt helper\n",
        "def handle_partial_args(source_path):\n",
        "    source_path = link_paths(source_path, '*')\n",
        "    source_path = get_list_files(source_path, None)\n",
        "    source_path = list(map(lambda path : path + '/', source_path))\n",
        "    print(\"source path: %s\" % source_path)\n",
        "\n",
        "    if len(source_path) == 0 or source_path[len(source_path)-1][-5:-1] == '.xml':\n",
        "        return th.source_path_warnings()\n",
        "    else:\n",
        "        folder_level = source_path[0].count('/')-1\n",
        "        print(\"folder destination level: %s\" % folder_level)\n",
        "        return source_path, folder_level\n",
        "\n",
        "def get_txt_text(file, length):\n",
        "    for index in range(length):\n",
        "        text = file.readline()\n",
        "    return text\n",
        "\n",
        "def fill_dataframe(data_frame, classifications_df, id_, classcode, abstract, claim, description):\n",
        "    if classcode != \"\":\n",
        "        # shrink the set to only_top_classes? TRUE/FALSE\n",
        "        classcode = cut_down(classcode, 4, ['H', 'B', 'C'], False) # H, B, C\n",
        "        data_frame.loc[data_frame.shape[0] + 1] = [id_, abstract, claim, description, classcode]\n",
        "        classifications_df = calculate_class_distribution(classcode, classifications_df)\n",
        "\n",
        "def handle_patent_file(data_frame, classifications_df, path_filename):\n",
        "    file = open(path_filename, \"r\")\n",
        "    id_ = get_patent_id(path_filename)\n",
        "    kind = get_txt_text(file, 1).strip()\n",
        "    if kind == 'A1':\n",
        "        classcode = get_txt_text(file, 1).strip()\n",
        "        applicant = get_txt_text(file, 1).strip()\n",
        "\n",
        "        abstract = get_txt_text(file, 1).strip()\n",
        "        citations = get_txt_text(file, 1).strip()\n",
        "        file.close()\n",
        "\n",
        "        fill_dataframe(data_frame, classifications_df, id_, classcode, abstract, None, None)\n",
        "    elif kind == 'B1':\n",
        "        classcode = get_txt_text(file, 1).strip()\n",
        "        id_respective_document = get_txt_text(file, 1).strip()\n",
        "\n",
        "        # abstract = get_txt_text(file, 1).strip()\n",
        "        claim = get_txt_text(file, 1).strip()\n",
        "        description = get_txt_text(file, 1).strip()\n",
        "        # citations = get_txt_text(file, 1).strip()\n",
        "        file.close()\n",
        "\n",
        "        fill_dataframe(data_frame, classifications_df, id_, classcode, None, claim, description)\n",
        "    else:\n",
        "        if kind == 'A1B1':\n",
        "            print(\"eu_mix_patent !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        else:\n",
        "            print(\"us_patent     !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "        classcode = get_txt_text(file, 1).strip()\n",
        "        applicant = get_txt_text(file, 1).strip()\n",
        "\n",
        "        abstract = get_txt_text(file, 1).strip()\n",
        "        claim = get_txt_text(file, 1).strip()\n",
        "        description = get_txt_text(file, 1).strip()\n",
        "        citations = get_txt_text(file, 1).strip()\n",
        "        file.close()\n",
        "\n",
        "        fill_dataframe(data_frame, classifications_df, id_, classcode, abstract, claim, description)\n",
        "    return id_\n",
        "\n",
        "def handle_path_patent(data_frame, classifications_df, path):\n",
        "    return list(map(lambda path_filename : handle_patent_file(data_frame, classifications_df, path_filename), get_list_files(path, 'txt')))\n",
        "\n",
        "def load_data(source_path):\n",
        "    print('###  reading patents  ###')\n",
        "    \"\"\" load_data \"\"\"\n",
        "    data_frame = pd.DataFrame(columns=['abstract', 'claim', 'description', 'classification'])\n",
        "    classifications_df = pd.DataFrame(columns=['class', 'count'])\n",
        "    patent_ids = []\n",
        "\n",
        "    patent_ids = list(map(lambda path : handle_path_patent(data_frame, classifications_df, path), tqdm(source_path)))\n",
        "    patent_ids = get_flat_list(patent_ids)\n",
        "\n",
        "    data_frame['id'] = data_frame.index\n",
        "    classifications_df.sort_values(by=['count'], ascending=False, inplace=True, kind='quicksort')\n",
        "    return patent_ids, data_frame, classifications_df\n",
        "\n",
        "def handle_row(row, ids_list):\n",
        "    if isinstance(row, pd.Series):\n",
        "        try:\n",
        "            id_, patent_id, text, class_ = row.tolist()\n",
        "        except:\n",
        "            patent_id, text, class_ = row.tolist()\n",
        "        tokens = tokenize_text(text)\n",
        "        if len(tokens) < 2:\n",
        "            ids_list.append(patent_id) \n",
        "\n",
        "def check_out_for_whitespaces(text):\n",
        "    if isinstance(text, str):\n",
        "        return ' '.join([element for element in tokenize_text(text) if len(element) > 2 and len(element) < 31])\n",
        "\n",
        "def check_out_empty_texts_and_wrong_classcodes(data_frame):\n",
        "    print('dataframe shape: ', data_frame.shape)\n",
        "    ids_list = []\n",
        "    data_frame.apply(lambda row : handle_row(row, ids_list), axis=1)  \n",
        "    data_frame.set_index(data_frame['patent_id'], inplace=True)\n",
        "    \n",
        "    data_frame.drop(ids_list, axis=0, inplace=True)\n",
        "\n",
        "    data_frame['text'] = data_frame['text'].apply(lambda text : check_out_for_whitespaces(text))\n",
        "    print('ids_list: ', ids_list)\n",
        "    print('dataframe shape: ', data_frame.shape)\n",
        "    return data_frame\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "def get_final_df(patent_ids, temp_df, classif_type):\n",
        "    classification_target = 'description_claim_abstract_title'\n",
        "\n",
        "    data_frame = pd.DataFrame(columns=['id_', 'patent_id', 'text', 'classification'])\n",
        "\n",
        "    if temp_df.shape[1] == 5:\n",
        "        data_frame['patent_id'] = temp_df['patent_id']\n",
        "    else:\n",
        "        data_frame[\"patent_id\"] = patent_ids\n",
        "\n",
        "    # textual_information = temp_df[\"abstract\"]\n",
        "    # textual_information = temp_df[\"claim\"]\n",
        "    # textual_information = temp_df[\"description\"]\n",
        "    textual_information = temp_df[\"abstract\"].str.cat(temp_df[\"claim\"], sep =\" \", na_rep=\" \").str.cat(temp_df[\"description\"], sep =\" \", na_rep=\" \")\n",
        "    data_frame['text'] = textual_information\n",
        "\n",
        "    # data_frame['text'] = data_frame['text'].apply(lambda text : clean_text(text))\n",
        "    data_frame = check_out_empty_texts_and_wrong_classcodes(data_frame)\n",
        "\n",
        "    classification_types = get_classifications(temp_df)\n",
        "    data_frame[\"classification\"] = classification_types[classif_type]\n",
        "    return data_frame, classification_target, classif_type"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i6cyHCvwcIKT",
        "colab": {}
      },
      "source": [
        "# tool helper\n",
        "def get_flat_list(list_of_lists):\n",
        "    return [element for elements in list_of_lists for element in elements]\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return text.split()\n",
        "\n",
        "def get_string_from_list(list_, linking_string):\n",
        "    return linking_string.join(element for element in list_ if isinstance(element, str))\n",
        "\n",
        "def cut_down(classification, index, top_classes, only_top_classes):\n",
        "    temp_list = tokenize_text(classification)\n",
        "    if only_top_classes:\n",
        "        new_classification_list = list(set(filter(lambda element : element[:index] in top_classes, temp_list)))\n",
        "        new_classification = get_string_from_list(new_classification_list, ' ')\n",
        "    else:\n",
        "        new_classification_list = list(set(map(lambda element : element[:index], temp_list)))\n",
        "        new_classification = get_string_from_list(new_classification_list, ' ')\n",
        "    return new_classification\n",
        "\n",
        "def calculate_class_distribution(classification, classifications_df):\n",
        "    if isinstance(classification, str):\n",
        "        for _class in tokenize_text(classification):\n",
        "            if classifications_df['class'].str.contains(_class).any():\n",
        "                index = classifications_df.index[classifications_df['class'] == _class]\n",
        "                classifications_df.loc[index[0], ['count']] += 1\n",
        "            else:\n",
        "                classifications_df.loc[classifications_df.shape[0] + 1] = [_class, 1]\n",
        "        return classifications_df\n",
        "\n",
        "def tokenize_complex_text_in_set(text):\n",
        "    return set(map(lambda word : word, tokenize_text(text)))\n",
        "\n",
        "def get_set_from_index(index_set, data_set):\n",
        "    set_ = np.ndarray(shape=(index_set.shape[0], data_set.shape[1]))\n",
        "    for index, data_index in enumerate(index_set['text'].values):\n",
        "        set_[index-1] = data_set[data_index-1]\n",
        "    return set_, index_set['patent_id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j2raUZIFbrQN",
        "colab": {}
      },
      "source": [
        "# classification helper\n",
        "def get_train_test_from_data(X, Y):\n",
        "    return train_test_split(X, Y, random_state=0, test_size=.2, shuffle=True)\n",
        "\n",
        "def get_train_test_from_dataframe(data_frame):\n",
        "    return train_test_split(data_frame, random_state=0, test_size=.2, shuffle=True)\n",
        "\n",
        "def get_distinct_class_substrings(classification_list, first_int, second_int):\n",
        "    list_ = []\n",
        "    for element in classification_list:\n",
        "        for class_ in tokenize_text(element):\n",
        "            if class_[first_int:second_int] not in list_:\n",
        "                list_.append(class_[first_int:second_int])\n",
        "    list_.sort()\n",
        "    return list_\n",
        "\n",
        "def get_class_substrings(classification_list, first_int, second_int):\n",
        "    list_ = []\n",
        "    for element in classification_list:\n",
        "        string = \"\"\n",
        "        for class_ in tokenize_text(element):\n",
        "            if class_[first_int:second_int] not in string:\n",
        "                string += class_[first_int:second_int] + ' '\n",
        "        list_.append(string)\n",
        "    return list_\n",
        "\n",
        "def get_classifications(temp_df):\n",
        "    ## Load utility data\n",
        "    classifications = temp_df['classification'].tolist()\n",
        "\n",
        "    valid_sections = get_distinct_class_substrings(classifications, 0, 1)\n",
        "    valid_classes = get_distinct_class_substrings(classifications, 1, 3)\n",
        "    valid_subclasses = get_distinct_class_substrings(classifications, 3, 4)\n",
        "\n",
        "    sections = get_class_substrings(classifications, 0, 1)\n",
        "    classes = get_class_substrings(classifications, 0, 3)\n",
        "    subclasses = get_class_substrings(classifications, 0, 4)\n",
        "\n",
        "    classification_types = {\n",
        "        \"sections\": sections,\n",
        "        \"classes\": classes,\n",
        "        \"subclasses\": subclasses\n",
        "    }\n",
        "    return classification_types\n",
        "\n",
        "def save_training_set(training_set, model_name):\n",
        "    print('###  saving_training_set  ###')\n",
        "    root_location = get_root_location('data/saved_training_set/')\n",
        "    model_name = model_name.replace(\"/\", \"-\")\n",
        "    path = link_paths(root_location, 'training '+model_name+' '+str(datetime.now())[:-10]+'.npy')\n",
        "    np.save(path, training_set)\n",
        "\n",
        "def save_sets(sets_location, train_data, test_data, val_data, train_labels, test_labels, val_labels, settings):\n",
        "    try:\n",
        "        date = '01-01-2020'\n",
        "        actual_sets_location = join_paths(sets_location, date)\n",
        "        with open(link_paths(actual_sets_location, 'training_set '+date+'.pkl'), \"wb\") as f:\n",
        "            pkl.dump([train_data, train_labels], f)\n",
        "        with open(link_paths(actual_sets_location, 'testing_set '+date+'.pkl'), \"wb\") as f:\n",
        "            pkl.dump([test_data, test_labels], f)\n",
        "        with open(link_paths(actual_sets_location, 'validation_set '+date+'.pkl'), \"wb\") as f:\n",
        "            pkl.dump([val_data, val_labels], f)\n",
        "        with open(link_paths(actual_sets_location, 'settings '+date+'.pkl'), \"wb\") as f:\n",
        "            pkl.dump(settings, f)\n",
        "    except:\n",
        "        print('A problem occurred while saving the sets!')\n",
        "\n",
        "def load_sets(sets_location, date='01-01-2020'):\n",
        "    try:\n",
        "        actual_sets_location = join_paths(sets_location, date)\n",
        "        with open(link_paths(actual_sets_location, 'training_set '+date+'.pkl'), \"rb\") as f:\n",
        "            train_data, train_labels = pkl.load(f)\n",
        "        with open(link_paths(actual_sets_location, 'testing_set '+date+'.pkl'), \"rb\") as f:\n",
        "            test_data, test_labels = pkl.load(f)\n",
        "        with open(link_paths(actual_sets_location, 'validation_set '+date+'.pkl'), \"rb\") as f:\n",
        "            val_data, val_labels = pkl.load(f)\n",
        "        with open(link_paths(actual_sets_location, 'settings '+date+'.pkl'), \"rb\") as f:\n",
        "            settings = pkl.load(f)\n",
        "            # classes, n_classes, vocab_processor, len_vocabulary = pkl.load(f)\n",
        "        return train_data, test_data, val_data, train_labels, test_labels, val_labels, settings\n",
        "    except:\n",
        "        print('A problem occurred while loading the sets!')\n",
        "        return None, None, None, None, None, None, None\n",
        "\n",
        "def save_data_frame(script_key, data_frame, csvfile):\n",
        "    path_to_csv = get_root_location('model_dataframe/')\n",
        "    date = datetime.now().isoformat()\n",
        "    if csvfile:\n",
        "        output_path = fh.link_paths(path_to_csv, csvfile)\n",
        "    else:\n",
        "        output_path = fh.link_paths(path_to_csv, 'dataframe '+date+'.csv')\n",
        "\n",
        "    data_frame.to_csv(output_path, index=False, sep=',', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
        "\n",
        "def load_data_frame(script_key, csvfile, date='01-01-2020'):\n",
        "    path_to_csv = get_root_location('model_dataframe/')\n",
        "    if csvfile:\n",
        "        input_path = link_paths(path_to_csv, csvfile)\n",
        "    else:\n",
        "        input_path = link_paths(path_to_csv, 'dataframe '+date+'.csv')\n",
        "\n",
        "    data_frame = pd.read_csv(input_path, sep=',', quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \", header=None, engine='python')\n",
        "    data_frame.columns = ['patent_id', 'text', 'classification']\n",
        "    \n",
        "    # data_frame['text'] = data_frame['text'].apply(lambda text : clean_text(text))\n",
        "    data_frame = check_out_empty_texts_and_wrong_classcodes(data_frame)\n",
        "    \n",
        "    classification_df = pd.DataFrame(columns=['class', 'count'])\n",
        "    # data_frame['classification'].apply(lambda class_ : calculate_class_distribution(class_, classification_df))\n",
        "    return data_frame, classification_df\n",
        "\n",
        "def apply_simple_binarizer(classification, classes):\n",
        "    print('###  label_binarizer  ###')\n",
        "    binarized_classification = label_binarize(classification, classes=classes)\n",
        "    return binarized_classification, classes, binarized_classification.shape[1]\n",
        "\n",
        "# TODO: may be the same as the simple\n",
        "def apply_label_binarizer(classification):\n",
        "    lb = LabelBinarizer()\n",
        "    return lb.fit_transform(classification)\n",
        "\n",
        "def apply_multilabel_binarizer(data_frame):\n",
        "    print('###  multi_label_binarizer  ###')\n",
        "    ################################################ classification: from text to sparse binary matrix [[0, 1, 0],[1, 0, 1]]\n",
        "    temp_classification = data_frame.apply(lambda row : tokenize_complex_text_in_set(row['classification']), axis=1)\n",
        "    df_to_list = temp_classification.tolist()\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    mlb.fit(df_to_list)\n",
        "    classes = list(mlb.classes_)\n",
        "    return mlb.transform(df_to_list), classes, len(classes)\n",
        "\n",
        "def apply_tfidf_vectorizer_fit_transform(data_frame):\n",
        "    # list of strings, which are consequently made of words (no stopwords, stemming already applied ...) - preprocessed text\n",
        "    print('###  tfidf_vectorizer_with_lambda  ###')\n",
        "    vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
        "    return vectorizer.fit_transform(data_frame['text'].apply(lambda x : np.str_(x))), data_frame['patent_id'], vectorizer\n",
        "\n",
        "def apply_tfidf_vectorizer_fit(data_frame):\n",
        "    print('###  tfidf_vectorizer_text  ###')\n",
        "    vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
        "    vectorizer.fit(data_frame['text'].apply(lambda x : np.str_(x)))\n",
        "    return vectorizer\n",
        "\n",
        "def apply_tfidf_vectorizer_transform(text, vectorizer):\n",
        "    return vectorizer.transform(text.apply(lambda x : np.str_(x)))\n",
        "\n",
        "def apply_word2vec_word_averaging(data_frame):\n",
        "    print('###  word2vec_word_averaging_vectorizer  ###')\n",
        "    path_ = current_path[:current_path.rfind('/', 0, -8)] + \"/data/GoogleNews-vectors-negative300.bin\"\n",
        "    print(\"google vectors : \", path_)\n",
        "    try:\n",
        "        wv = gensim.models.KeyedVectors.load_word2vec_format(path_, binary=True)\n",
        "    except:\n",
        "        print(\"unable to find word2vec model from google, downloading...\")\n",
        "        wv = gensim.models.KeyedVectors.load_word2vec_format(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "        print(\"done...\")\n",
        "    wv.init_sims(replace=True)\n",
        "    helper_word2vec = Word2VecHelper()\n",
        "\n",
        "    text_tokenized = data_frame.apply(lambda row : helper_word2vec.w2v_tokenize_text(row['text']), axis=1).values\n",
        "    return helper_word2vec.word_averaging_list(wv, text_tokenized)\n",
        "\n",
        "def apply_doc2vec(data_frame, type_):\n",
        "    Y, classes, n_classes = apply_classification_vectorizer(type_, data_frame)\n",
        "    print('finisched class vect')\n",
        "    X_train, X_test, y_train, y_test = get_train_test_from_data(data_frame, Y)\n",
        "    print('finisched get train test')\n",
        "    patent_ids = X_train['patent_id']\n",
        "    print('finisched ids')\n",
        "    helper_doc2vec = Dov2VecHelper()\n",
        "    print('finisched doc2vec helpers')\n",
        "    X_train = helper_doc2vec.label_sentences(X_train['text'], 'Train')\n",
        "    print('finisched label sent')\n",
        "    X_test = helper_doc2vec.label_sentences(X_test['text'], 'Test')\n",
        "    print('finisched label sent')\n",
        "    all_data = X_train + X_test\n",
        "    print('finisched all data')\n",
        "    model_dbow = train_doc2vec(all_data)\n",
        "    print('finisched train doc2vec')\n",
        "    train_vectors_dbow = helper_doc2vec.get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
        "    print('finisched get vect')\n",
        "    test_vectors_dbow = helper_doc2vec.get_vectors(model_dbow, len(X_test), 300, 'Test')\n",
        "    print('finisched get vect')\n",
        "    return train_vectors_dbow, test_vectors_dbow,  y_train, y_test, classes, n_classes, patent_ids\n",
        "\n",
        "def apply_standard_vectorizer(data_frame, type_):\n",
        "    Y, classes, n_classes = apply_classification_vectorizer(type_, data_frame)\n",
        "    X, vocab_processor, len_vocabulary = apply_vocabulary_processor(data_frame['text'])\n",
        "    # a list of the words used in the text, identified by a unique number for each different word\n",
        "\n",
        "    X_train, X_test, y_train, y_test = get_train_test_from_data(X, Y)\n",
        "\n",
        "    print(\"Vocabulary Size: {:d}\".format(len_vocabulary))\n",
        "    print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_test)))\n",
        "    return X_train, X_test, y_train, y_test, classes, n_classes, vocab_processor, len_vocabulary\n",
        "\n",
        "def set_string_for_fasttext(item):\n",
        "    return str(item).replace(' or ', ' ').replace(', or ', ' ').replace(',', ' ').replace(',', '__label__').replace('$$', ' ').replace('$', ' ').replace(' ', ' __label__').replace('___', '__')\n",
        "\n",
        "def apply_classification_vectorizer(type_, data_frame):\n",
        "    classification = data_frame['classification']\n",
        "    if type_ == 'simple':\n",
        "        classes = ['H', 'B', 'C'] # useful if i need to shrink the set of classes\n",
        "        return apply_simple_binarizer(classification, classes)\n",
        "    elif type_ == 'label_binarizer':\n",
        "        return apply_label_binarizer(classification), None, 0\n",
        "    elif type_ == 'multi_label':\n",
        "        return apply_multilabel_binarizer(data_frame)\n",
        "    elif type_ == 'fasttext':\n",
        "        return ['__label__'+set_string_for_fasttext(item) for item in data_frame['classification']], None, 0\n",
        "    return classification, None, 0\n",
        "\n",
        "def apply_df_vectorizer(data_frame, type_, classification_type, model_name):\n",
        "    # type_ = \"doc2vec\"\n",
        "    # classification_type = \"multi_label\"\n",
        "    if type_ == 'doc2vec':\n",
        "        X_train, X_test, Y_train, Y_test, classes, n_classes, patent_ids = apply_doc2vec(data_frame, classification_type)\n",
        "        # array - not numpy\n",
        "        print('finisched apply doc2vec')\n",
        "        vocab_processor, len_vocabulary = None, 0\n",
        "    elif type_ == 'standard':\n",
        "        standard_results = apply_standard_vectorizer(data_frame, classification_type)\n",
        "        X_train, X_test, Y_train, Y_test, classes, n_classes, vocab_processor, len_vocabulary = standard_results\n",
        "        patent_ids = data_frame['patent_id']\n",
        "    else:\n",
        "        Y_vect, classes, n_classes = apply_classification_vectorizer(classification_type, data_frame)\n",
        "        vocab_processor, len_vocabulary = None, 0\n",
        "        if type_ == 'tfidf_fit_transform': # not sure it remains the same order\n",
        "            X_vect = pd.DataFrame({'text' : data_frame['text'], 'patent_id' : data_frame['patent_id']})\n",
        "            X_train, X_test, Y_train, Y_test = get_train_test_from_data(X_vect, Y_vect)\n",
        "\n",
        "            patent_ids = X_train['patent_id']\n",
        "            print('almost started tfidf')\n",
        "            vectorizer = apply_tfidf_vectorizer_fit(data_frame)\n",
        "            print('applied tfidf')\n",
        "            X_train = apply_tfidf_vectorizer_transform(X_train['text'], vectorizer)\n",
        "            print('transformed train')\n",
        "            X_test = apply_tfidf_vectorizer_transform(X_test['text'], vectorizer)\n",
        "            print('transformed test')\n",
        "            # csr matrix\n",
        "        elif type_ == 'word2vec': # required google pre-trained vectors, it starts downloading if you don't have\n",
        "            X_vect = apply_word2vec_word_averaging(data_frame)\n",
        "            # ndarray\n",
        "            print('finished word2vec word averaging')\n",
        "            text_indexes = data_frame.index.values\n",
        "\n",
        "            X_vect_temp = pd.DataFrame({'text' : text_indexes, 'patent_id' : data_frame['patent_id']})\n",
        "            X_train_temp, X_test_temp, Y_train, Y_test = get_train_test_from_data(X_vect_temp, Y_vect)\n",
        "\n",
        "            X_train, patent_ids = get_set_from_index(X_train_temp, X_vect)\n",
        "            X_test, _ = get_set_from_index(X_test_temp, X_vect)\n",
        "            print('finished word2vec vectorizer')\n",
        "        else:\n",
        "            data_frame.drop(columns=['classification'])\n",
        "            X_train, X_test, Y_train, Y_test = get_train_test_from_data(data_frame, Y_vect)\n",
        "            return X_train, X_test, Y_train, Y_test, classes, n_classes, vocab_processor, len_vocabulary\n",
        "    save_training_set(patent_ids, model_name)\n",
        "    return X_train, X_test, Y_train, Y_test, classes, n_classes, vocab_processor, len_vocabulary\n",
        "\n",
        "def get_csv_path(model_key):\n",
        "    root_location = get_root_location('data/')\n",
        "    return link_paths(root_location, 'lstm_results.csv')\n",
        "#     return 'content/drive/My\\ Drive/Colab\\ Notebooks/data/conv_results.csv'\n",
        "\n",
        "def apply_method_to_create_metrics(tuple_):\n",
        "    return list(tuple_) if tuple_ else 'None'\n",
        "\n",
        "def get_parameters_values(parameters):\n",
        "    parameters.replace(\" \", \"\")\n",
        "    return list(map(lambda token : token, parameters.split(' ')))\n",
        "\n",
        "def get_parameters_list(model, metrics, parameters, classif_approach, classif_level, classif_type, dataset_location):\n",
        "    list_ = [model]\n",
        "    list_ += list(map(lambda item : item, metrics))\n",
        "    list_ += [classif_approach, classif_level, classif_type]\n",
        "    list_ += list(map(lambda item : item, parameters))\n",
        "    list_ += [dataset_location]\n",
        "    return list_\n",
        "\n",
        "def get_metrics_values(metrics):\n",
        "    return list(map(lambda tuple_ : apply_method_to_create_metrics(tuple_), metrics))\n",
        "\n",
        "def get_sequential_LSTM_metrics_values(metrics):\n",
        "    micro = [\"precision:\"+str(metrics[\"precision_micro\"]), \"recall:\"+str(metrics[\"recall_micro\"]), \"f1:\"+str(metrics[\"f1_micro\"])]\n",
        "    macro = [\"precision:\"+str(metrics[\"precision_macro\"]), \"recall:\"+str(metrics[\"recall_macro\"]), \"f1:\"+str(metrics[\"f1_macro\"])]\n",
        "    tops = [\"top_1:\"+str(metrics[\"top_1\"]), \"top_3:\"+str(metrics[\"top_3\"]), \"top_5:\"+str(metrics[\"top_5\"])]\n",
        "    return [str(metrics[\"coverage_error\"]), micro, macro, tops]\n",
        "\n",
        "def get_sequential_layers_values(parameters):\n",
        "    return [list(map(lambda token : token, tokenize_text(parameters[:-1])))]\n",
        "\n",
        "def write_dataframe_as_csv(data_frame, path_to_csv):\n",
        "    if os.path.isfile(path_to_csv):\n",
        "        with open(path_to_csv, 'a') as f:\n",
        "            data_frame.to_csv(f, sep=',', header=False)\n",
        "    else:\n",
        "        data_frame.to_csv(path_to_csv, sep=',', header=True)\n",
        "\n",
        "settings = {\n",
        "    \"Sequential\" : {\n",
        "                            \"results_file_name\" : \"data/models_results/sequential_results.csv\",\n",
        "                            \"metrics\" : ['loss', 'accuracy', 'mse'],\n",
        "                            \"parameters\" : ['layers'],\n",
        "    },\n",
        "    \"Sequential Test\" : {\n",
        "                            \"results_file_name\" : \"data/models_results/sequential_results.csv\",\n",
        "                            \"metrics\" : ['loss', 'accuracy', 'mse', 'micro', 'macro'],\n",
        "                            \"parameters\" : ['layers'],\n",
        "    },\n",
        "    \"Sequential Val\" : {\n",
        "                            \"results_file_name\" : \"data/models_results/sequential_results.csv\",\n",
        "                            \"metrics\" : ['loss', 'accuracy', 'mse', 'micro', 'macro'],\n",
        "                            \"parameters\" : ['layers'],\n",
        "    }\n",
        "}\n",
        "\n",
        "def get_saving_dataframe(model_key, metrics_values, parameters_values, classif_approach, classif_level, classif_type, dataset_location):\n",
        "    columns_list = get_parameters_list('model_name', settings[model_key][\"metrics\"], settings[model_key][\"parameters\"], 'approach', 'level', 'type', 'dataset_location')\n",
        "    values_list = get_parameters_list(model_key, metrics_values, parameters_values, classif_approach, classif_level, classif_type, dataset_location)\n",
        "    data_frame = pd.DataFrame(columns=columns_list)\n",
        "    data_frame.loc[data_frame.shape[0] + 1] = values_list\n",
        "    return data_frame\n",
        "\n",
        "def save_results(model_key, metrics, parameters, classif_approach, classif_level, classif_type, dataset_location):\n",
        "    print('###  saving_results  ###')\n",
        "    path_to_csv = get_csv_path(model_key)\n",
        "\n",
        "    if model_key == 'Sequential':\n",
        "        metrics = list(map(lambda metric : [metric], metrics))\n",
        "        # metrics = [[metric] for metric in metrics]\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    elif model_key == 'Sequential Test' or 'Sequential Val':\n",
        "        metrics = [[-1], [-1], [-1], # metrics['loss'], metrics['accuracy'], metrics['mse'],\n",
        "                   [metrics['precision_micro'], metrics['recall_micro'], metrics['f1_micro']],\n",
        "                   [metrics['precision_macro'], metrics['recall_macro'], metrics['f1_macro']]]\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    elif model_key == 'FastText':\n",
        "        metrics_values = metrics[1:3]\n",
        "        parameters_values = [parameters]\n",
        "    elif model_key == 'Sequential_LSTM':\n",
        "        temp_metrics = metrics\n",
        "        del temp_metrics[\"total_positive\"], temp_metrics[\"average_num_of_labels\"]\n",
        "        metrics_values = get_sequential_LSTM_metrics_values(temp_metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    else:\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_parameters_values(parameters)\n",
        "\n",
        "    data_frame = get_saving_dataframe(model_key, metrics_values, parameters_values, classif_approach, classif_level, classif_type, dataset_location)\n",
        "    write_dataframe_as_csv(data_frame, path_to_csv)\n",
        "\n",
        "def get_sequential_classifier_information(model):\n",
        "    text = str(model)\n",
        "    string_list = []\n",
        "    model.summary(print_fn=lambda x: string_list.append(x))\n",
        "    layers = ' '.join(string_list)\n",
        "\n",
        "    parameters = \"\"\n",
        "    for index, el in enumerate(layers.split(' (')):\n",
        "        if index > 0 and index < len(layers.split(' ('))-1:\n",
        "            if len(el.split(' ')[-1]) >= 5:\n",
        "                parameters += el.split(' ')[-1] + \" \"\n",
        "\n",
        "    return text.split(' ')[0].split('.')[-1], parameters\n",
        "\n",
        "def save_results_function(model_key, metrics, parameters, classif_approach, classif_level, classif_type, dataset_location):\n",
        "    print('###  saving_results  ###')\n",
        "    path_to_csv = get_csv_path(model_key)\n",
        "\n",
        "    if model_key == 'Sequential':\n",
        "        metrics = list(map(lambda metric : [metric], metrics))\n",
        "        # metrics = [[metric] for metric in metrics]\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    elif model_key == 'Sequential Test' or 'Sequential Val':\n",
        "        metrics = [[-1], [-1], [-1], # metrics['loss'], metrics['accuracy'], metrics['mse'],\n",
        "                   [metrics['precision_micro'], metrics['recall_micro'], metrics['f1_micro']],\n",
        "                   [metrics['precision_macro'], metrics['recall_macro'], metrics['f1_macro']]]\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    elif model_key == 'FastText':\n",
        "        metrics_values = metrics[1:3]\n",
        "        parameters_values = [parameters]\n",
        "    elif model_key == 'Sequential_LSTM':\n",
        "        temp_metrics = metrics\n",
        "        del temp_metrics[\"total_positive\"], temp_metrics[\"average_num_of_labels\"]\n",
        "        metrics_values = get_sequential_LSTM_metrics_values(temp_metrics)\n",
        "        parameters_values = get_sequential_layers_values(parameters)\n",
        "    else:\n",
        "        metrics_values = get_metrics_values(metrics)\n",
        "        parameters_values = get_parameters_values(parameters)\n",
        "\n",
        "    data_frame = get_saving_dataframe(model_key, metrics_values, parameters_values, classif_approach, classif_level, classif_type, dataset_location)\n",
        "    write_dataframe_as_csv(data_frame, path_to_csv)\n",
        "\n",
        "def fill_matrix(data_matrix, source_dict, docs_list):\n",
        "    \"\"\"\n",
        "    the use_get flag is for doc2vec_model.docvecs since it doesnt support .get(), so we catch the exception and\n",
        "    fill with zeros in that case. This should really happen very rarely (if ever) so this exception handling\n",
        "    should not be a drain on performance\n",
        "    \"\"\"\n",
        "    for i, doc_id in enumerate(docs_list):\n",
        "        child_ids = doc_id\n",
        "        j = 0\n",
        "        # try:\n",
        "        if source_dict[child_ids] is not None:\n",
        "            data_matrix[i][j] = source_dict[child_ids]\n",
        "        else:\n",
        "            data_matrix[i][j] = [0]\n",
        "        # except:\n",
        "        #     data_matrix[i][j] = [0]\n",
        "\n",
        "def batch_generator(input_file, label_file, batch_size, QUEUE_SIZE, is_mlp=False, validate=False):\n",
        "    q = Queue(maxsize=QUEUE_SIZE)\n",
        "    p = ArrayReader(input_file, label_file, q, batch_size, is_mlp, validate)\n",
        "    p.start()\n",
        "    while True:\n",
        "        item = q.get()\n",
        "        if not item:\n",
        "            p.terminate()\n",
        "            print('Finished batch iteration')\n",
        "            raise StopIteration()\n",
        "        else:\n",
        "            yield item\n",
        "\n",
        "class ArrayReader(Process):\n",
        "    def __init__(self, input_file, label_file, out_queue, batch_size, is_mlp=False, validate=False):\n",
        "        super(ArrayReader, self).__init__()\n",
        "        self.is_mlp = is_mlp\n",
        "        self.validate = validate\n",
        "        self.q = out_queue\n",
        "        self.batch_size = batch_size\n",
        "        self.input_file = input_file\n",
        "        self.label_file = label_file\n",
        "\n",
        "    def run(self):\n",
        "        # x_file = np.load(self.input_file, mmap_mode='r')\n",
        "        # y_file = np.load(self.label_file, mmap_mode='r')\n",
        "        x_file = self.input_file\n",
        "        y_file = self.label_file\n",
        "        start_item = 0\n",
        "        num_iter = 0\n",
        "        while True:\n",
        "            if start_item > y_file.shape[0]:\n",
        "                # print('in new epoch for {}'.format(os.path.basename(self.input_file)))\n",
        "                print('\\nin new epoch for {}'.format(os.path.basename('X_data, y_train with validation data')))\n",
        "                start_item = 0\n",
        "            y_batch = y_file[start_item: start_item + self.batch_size]\n",
        "            x_batch = x_file[start_item: start_item + self.batch_size]\n",
        "            if self.is_mlp:\n",
        "                x_batch = np.reshape(x_batch, (x_batch.shape[0], x_batch.shape[1] * x_batch.shape[2]))\n",
        "            start_item += self.batch_size\n",
        "            num_iter += 1\n",
        "            try:\n",
        "                self.q.put((x_batch, y_batch), block=True)\n",
        "            except:\n",
        "                return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZAPUCdbtkop",
        "colab": {}
      },
      "source": [
        "# word model helper\n",
        "class Word2VecHelper():\n",
        "    def __init__(self):\n",
        "        print('###  word2vec_vectorizer  ###')\n",
        "        self.tokens = []\n",
        "        self.mean = []\n",
        "\n",
        "    def w2v_tokenize_text(self, text):\n",
        "        self.tokens = []\n",
        "        for word in tokenize_text(text):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            self.tokens.append(word)\n",
        "        return self.tokens\n",
        "\n",
        "    def word_averaging(self, wv, words):\n",
        "        all_words = set()\n",
        "        self.mean = []\n",
        "\n",
        "        for word in words:\n",
        "            if isinstance(word, np.ndarray):\n",
        "                self.mean.append(word)\n",
        "            elif word in wv.vocab:\n",
        "                self.mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "                all_words.add(wv.vocab[word].index)\n",
        "\n",
        "        if not self.mean:\n",
        "            print(\"POSSIBLE ERROR IN WORD2VECHELPER: cannot compute similarity with no input %s\", words)\n",
        "            return np.zeros(wv.vector_size,)\n",
        "\n",
        "        self.mean = gensim.matutils.unitvec(np.array(self.mean).mean(axis=0)).astype(np.float32)\n",
        "        return self.mean\n",
        "\n",
        "    def  word_averaging_list(self, wv, text_list):\n",
        "        return np.vstack([self.word_averaging(wv, post) for post in text_list])\n",
        "\n",
        "class Dov2VecHelper():\n",
        "    def __init__(self):\n",
        "        print('###  doc2vec_vectorizer  ###')\n",
        "        self.labeled = []\n",
        "        self.vectors = []\n",
        "\n",
        "    def label_sentences(self, corpus, label_type):\n",
        "        \"\"\"\n",
        "        Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
        "        We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
        "        a dummy index of the post.\n",
        "        \"\"\"\n",
        "        self.labeled = []\n",
        "        for i, v in enumerate(corpus):\n",
        "            label = label_type + '_' + str(i)\n",
        "            self.labeled.append(TaggedDocument(tokenize_text(v), [label]))\n",
        "        return self.labeled\n",
        "\n",
        "    def get_vectors(self, model, corpus_size, vectors_size, vectors_type):\n",
        "        \"\"\"\n",
        "        Get vectors from trained doc2vec model\n",
        "        :param doc2vec_model: Trained Doc2Vec model\n",
        "        :param corpus_size: Size of the data\n",
        "        :param vectors_size: Size of the embedding vectors\n",
        "        :param vectors_type: Training or Testing vectors\n",
        "        :return: list of vectors\n",
        "        \"\"\"\n",
        "        self.vectors = np.zeros((corpus_size, vectors_size))\n",
        "        for i in range(0, corpus_size):\n",
        "            prefix = vectors_type + '_' + str(i)\n",
        "            self.vectors[i] = model.docvecs[prefix]\n",
        "        return self.vectors\n",
        "\n",
        "def train_doc2vec(data_):\n",
        "    cores = multiprocessing.cpu_count()\n",
        "    model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065, sample=0, workers=cores)\n",
        "    model_dbow.build_vocab([x for x in tqdm(data_)])\n",
        "\n",
        "    for epoch in range(30):\n",
        "        model_dbow.train(utils_shuffle_rows([x for x in tqdm(data_)]), total_examples=len(data_), epochs=1)\n",
        "        model_dbow.alpha -= 0.002\n",
        "        model_dbow.min_alpha = model_dbow.alpha\n",
        "    return model_dbow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MyZcVylzqpsN",
        "colab": {}
      },
      "source": [
        "# metrics helper\n",
        "get_binary_0_5 = lambda x: 1 if x > 0.15 else 0\n",
        "get_binary_0_5 = np.vectorize(get_binary_0_5)\n",
        "\n",
        "metrics_graph_ranges = {\n",
        "    'sections': {'min':0, 'max': 0.5},\n",
        "    'classes': {'min':0, 'max': 0.05},\n",
        "    'subclasses': {'min':0, 'max': 0.05}\n",
        "}\n",
        "\n",
        "def get_binary_classification(predictions, threshold):\n",
        "    binary_predictions = lambda prediction : 1 if prediction > threshold else 0\n",
        "    return np.vectorize(binary_predictions)\n",
        "\n",
        "def display_sequential_metrics(algorithm, metrics):\n",
        "    print('###  calculating_metrics  ###')\n",
        "    print('@@@  ' + algorithm + '  @@@')\n",
        "    print(\"Over all labels - Coverage error: {:.3f}, Average labels: {:.3f}\".format(\n",
        "        metrics['coverage_error'], metrics['average_num_of_labels']))\n",
        "    print(\"Percentage - Top 1: {:.3f}, Top 3: {:.3f}, Top 5: {:.3f}\".format(\n",
        "        metrics['top_1'], metrics['top_3'], metrics['top_5']))\n",
        "    print(\"Macro - precision: {:.3f}, recall: {:.3f}, f1: {:.3f}\".format(\n",
        "        metrics['precision_macro'], metrics['recall_macro'], metrics['f1_macro']))\n",
        "    print(\"Micro - precision: {:.3f}, recall: {:.3f}, f1: {:.3f}\".format(\n",
        "        metrics['precision_micro'], metrics['recall_micro'], metrics['f1_micro']))\n",
        "\n",
        "def get_top_N_percentage(y_score, y_true, max_N=3):\n",
        "    \"\"\"\n",
        "    Get percentage of correct labels that are in the top N scores\n",
        "    \"\"\"\n",
        "    num_all_true = 0\n",
        "    num_found_in_max_N = 0\n",
        "    for i in range(y_score.shape[0]):\n",
        "        y_score_row = y_score[i, :]\n",
        "        y_true_row = y_true[i, :]\n",
        "        desc_score_indices = np.argsort(y_score_row)[::-1]\n",
        "        true_indices = np.where(y_true_row ==1)[0]\n",
        "\n",
        "        num_true_in_row = len(true_indices)\n",
        "        num_all_true += num_true_in_row\n",
        "        for i, score_index in enumerate(desc_score_indices):\n",
        "            # only iterate through the score list till depth N, but make sure you also account for the case where\n",
        "            # the number of true labels for the current row is higher than N\n",
        "            if i >= max_N and i >= num_true_in_row:\n",
        "                break\n",
        "            if score_index in true_indices:\n",
        "                num_found_in_max_N += 1\n",
        "    return float(num_found_in_max_N) / num_all_true\n",
        "\n",
        "def get_sequential_metrics(y_true, y_score, y_binary_score):\n",
        "    \"\"\"\n",
        "    create the metrics object containing all relevant metrics\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "    metrics['total_positive'] = np.sum(np.sum(y_binary_score))\n",
        "\n",
        "    metrics['y_true'] = y_true\n",
        "    metrics['y_score'] = y_score\n",
        "    metrics['y_binary_score'] = y_binary_score\n",
        "\n",
        "    metrics['coverage_error'] = coverage_error(y_true, y_score)\n",
        "    metrics['average_num_of_labels'] = round(float(np.sum(np.sum(y_true, axis=1))) / y_true.shape[0], 2)\n",
        "\n",
        "    metrics['average_precision_micro'] = average_precision_score(y_true, y_binary_score, average='micro')\n",
        "    metrics['average_precision_macro'] = average_precision_score(y_true, y_binary_score, average='macro')\n",
        "\n",
        "    metrics['precision_micro'] = precision_score(y_true, y_binary_score, average='micro')\n",
        "    metrics['precision_macro'] = precision_score(y_true, y_binary_score, average='macro')\n",
        "    metrics['recall_micro'] = recall_score(y_true, y_binary_score, average='micro')\n",
        "    metrics['recall_macro'] = recall_score(y_true, y_binary_score, average='macro')\n",
        "    metrics['f1_micro'] = f1_score(y_true, y_binary_score, average='micro')\n",
        "    metrics['f1_macro'] = f1_score(y_true, y_binary_score, average='macro')\n",
        "\n",
        "    # only calculate those for cases with a small number of labels (sections only)\n",
        "    if y_true.shape[1] < 100:\n",
        "        precision_scores = np.zeros(y_true.shape[1])\n",
        "        for i in range(0, y_true.shape[1]):\n",
        "            precision_scores[i] = precision_score(y_true[:,i], y_binary_score[:,i])\n",
        "        metrics['precision_scores_array'] = precision_scores.tolist()\n",
        "\n",
        "        recall_scores = np.zeros(y_true.shape[1])\n",
        "        for i in range(0, y_true.shape[1]):\n",
        "            recall_scores[i] = recall_score(y_true[:,i], y_binary_score[:,i])\n",
        "        metrics['recall_scores_array'] = recall_scores.tolist()\n",
        "\n",
        "        f1_scores = np.zeros(y_true.shape[1])\n",
        "        for i in range(0, y_true.shape[1]):\n",
        "            f1_scores[i] = f1_score(y_true[:,i], y_binary_score[:,i])\n",
        "        metrics['f1_scores_array'] = f1_scores.tolist()\n",
        "\n",
        "    metrics['top_1'] = get_top_N_percentage(y_score, y_true, max_N=1)\n",
        "    metrics['top_3'] = get_top_N_percentage(y_score, y_true, max_N=3)\n",
        "    metrics['top_5'] = get_top_N_percentage(y_score, y_true, max_N=5)\n",
        "    return metrics\n",
        "\n",
        "def get_data_files(base_location, classif_type, level, data_type):\n",
        "    \"\"\"\n",
        "    get the files to load the data from for a certain classification type, level and data type\n",
        "    \"\"\"\n",
        "    data_file = os.path.join(base_location, data_type_file_dict[data_type].format(level))\n",
        "    labels_file = os.path.join(base_location, labels_type_file_dict[data_type].format(classif_type))\n",
        "    return data_file, labels_file\n",
        "\n",
        "def get_data(data_file, labels_file, mmap=False):\n",
        "    \"\"\"\n",
        "    load np data with a certain mmap configuration\n",
        "    \"\"\"\n",
        "    mmap_mode = None\n",
        "    if mmap == True:\n",
        "        mmap_mode = \"r\"\n",
        "    X_data = np.load(data_file, mmap_mode=mmap_mode)\n",
        "    y_data = np.load(labels_file, mmap_mode=mmap_mode)\n",
        "    return X_data, y_data\n",
        "\n",
        "def calculate_manual_metrics(algorithm, y_true, y_pred):\n",
        "    a, b = y_true.T.copy(order = 'C'), y_pred.T.copy(order = 'C')\n",
        "    \n",
        "    print('//////// \\ntrue_values:')\n",
        "    print(a)\n",
        "    print(a.shape)\n",
        "    print('//////// \\npredictions:')\n",
        "    print(b)\n",
        "    print(b.shape)\n",
        "\n",
        "    count = 0\n",
        "    count_tp, count_fp, count_tn, count_fn = 0, 0, 0, 0\n",
        "    temp_count_tp, temp_count_fp, temp_count_tn, temp_count_fn = 0, 0, 0, 0\n",
        "    temp_precision, temp_recall = [], []\n",
        "    for y_test_el, y_pred_el in zip(np.nditer(a), np.nditer(b)):\n",
        "        print(y_test_el, y_pred_el, end=', ')\n",
        "        count += 1\n",
        "        if y_pred_el == 1 and y_test_el == 1:\n",
        "            temp_count_tp += 1\n",
        "        if y_pred_el == 1 and y_test_el == 0:\n",
        "            temp_count_fp += 1\n",
        "        if y_pred_el == 0 and y_test_el == 0:\n",
        "            temp_count_tn += 1\n",
        "        if y_pred_el == 0 and y_test_el == 1:\n",
        "            temp_count_fn += 1\n",
        "        if count % y_true.shape[0] == 0:\n",
        "            print(' ', count)\n",
        "            if temp_count_tp+temp_count_fp != 0:\n",
        "                precision = temp_count_tp/(temp_count_tp+temp_count_fp)\n",
        "            else:\n",
        "                precision = 0\n",
        "            if temp_count_tp+temp_count_fn != 0:\n",
        "                recall = temp_count_tp/(temp_count_tp+temp_count_fn)\n",
        "            else:\n",
        "                recall = 0\n",
        "            temp_precision.append(precision)\n",
        "            temp_recall.append(recall)\n",
        "\n",
        "            count_tp += temp_count_tp\n",
        "            count_fp += temp_count_fp\n",
        "            count_tn += temp_count_tn\n",
        "            count_fn += temp_count_fn\n",
        "\n",
        "            temp_count_tp, temp_count_fp, temp_count_tn, temp_count_fn = 0, 0, 0, 0\n",
        "\n",
        "    print('\\nglobal - true positives : ', count_tp, 'true negatives : ', count_tn, 'false positives : ', count_fp, 'false negatives : ', count_fn)\n",
        "    print('per class - precision values to average: ', temp_precision)\n",
        "    print('per class - recall values to average: ', temp_recall)\n",
        "\n",
        "    accuracy = (count_tp+count_tn)/(count_tp+count_tn+count_fp+count_fn)\n",
        "    try:\n",
        "        precision = count_tp/(count_tp+count_fp)\n",
        "    except:\n",
        "        precision = 0\n",
        "    try:\n",
        "        recall = count_tp/(count_tp+count_fn)\n",
        "    except:\n",
        "        recall = 0\n",
        "    try:\n",
        "        f1_score = 2*(precision*recall)/(precision+recall)\n",
        "    except:\n",
        "        f1_score = 0\n",
        "\n",
        "    average_precision = sum(temp_precision)/len(temp_precision)\n",
        "    average_recall = sum(temp_recall)/len(temp_recall)\n",
        "    average_f1_score = 2*(average_precision*average_recall)/(average_precision+average_recall)\n",
        "\n",
        "    print('test accuracy : {0:0.5f}'.format(accuracy))\n",
        "    print('micro test precision : {0:0.5f},'.format(precision), ' macro test precision : {0:0.5f}'.format(average_precision))\n",
        "    print('micro test recall : {0:0.5f},'.format(recall), ' macro test recall : {0:0.5f}'.format(average_recall))\n",
        "    print('micro test f1_score : {0:0.5f},'.format(f1_score), ' macro test f1_score : {0:0.5f}'.format(average_f1_score))\n",
        "    return [-1,-1,-1,-1], [-1,-1,-1,-1], [accuracy, precision, recall, f1_score], [accuracy, average_precision, average_recall, average_f1_score]\n",
        "\n",
        "class MetricsCNNCallback(Callback):\n",
        "    \"\"\"\n",
        "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the\n",
        "    validation metrics\n",
        "    \"\"\"\n",
        "    def __init__(self, val_data, val_labels, patience):\n",
        "        super(MetricsCNNCallback, self).__init__()\n",
        "        self.val_data = val_data\n",
        "        self.val_labels = val_labels\n",
        "\n",
        "        self.patience = patience\n",
        "\n",
        "        self.best_val_loss = None\n",
        "        self.best_weights = None\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.epoch_index = 0\n",
        "\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "        self.metrics_dict = {}\n",
        "        self.best_val_loss = np.Inf\n",
        "        self.best_weights = np.Inf\n",
        "        self.best_validation_metrics = None\n",
        "\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "        self.val_predictions = None\n",
        "        self.binary_predictions = None\n",
        "        self.val_loss, self.val_acc, self.val_mse = 0, 0, 0\n",
        "        self.validation_metrics = {}\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.epoch_index += 1\n",
        "\n",
        "        actual_val_loss = logs.get('val_loss')\n",
        "        loss = logs.get('loss')\n",
        "        self.losses.append(loss)\n",
        "        self.val_losses.append(actual_val_loss)\n",
        "\n",
        "        if np.less(actual_val_loss, self.best_val_loss):\n",
        "            self.best_val_loss = actual_val_loss\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            print('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(actual_val_loss, 5)))\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if np.less(self.patience, self.wait):\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print('Restoring model weights from the end of the best epoch.')\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0:\n",
        "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))\n",
        "\n",
        "# class MetricsCallback():\n",
        "class MetricsCallback(Callback):\n",
        "    \"\"\"\n",
        "    Callback called by keras after each epoch. Records the best validation loss and periodically checks the\n",
        "    validation metrics\n",
        "    \"\"\"\n",
        "    def __init__(self, base_load_directory, classifications_type, level, batch_size, is_mlp=False):\n",
        "        MetricsCallback.EPOCHS_BEFORE_VALIDATION = 10\n",
        "        MetricsCallback.GRAPH_MIN = metrics_graph_ranges[classifications_type]['min']\n",
        "        MetricsCallback.GRAPH_MAX = metrics_graph_ranges[classifications_type]['max']\n",
        "        self.base_load_directory = base_load_directory\n",
        "        self.classifications_type = classifications_type\n",
        "        self.level = level\n",
        "        self.batch_size = batch_size\n",
        "        self.is_mlp = is_mlp\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.epoch_index = 0\n",
        "        self.val_loss_reductions = 0\n",
        "        self.metrics_dict = {}\n",
        "        self.best_val_loss = np.iinfo(np.int32).max\n",
        "        self.best_weights = None\n",
        "        self.best_validation_metrics = None\n",
        "\n",
        "        self.losses = []\n",
        "        self.val_losses = []\n",
        "        self.fig = plt.figure(figsize=(12,6), dpi=80)\n",
        "        self.ax = plt.subplot(111)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        QUEUE_SIZE = 100\n",
        "        self.epoch_index += 1\n",
        "        self.losses.append(logs['loss'])\n",
        "        self.val_losses.append(logs['val_loss'])\n",
        "        loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.losses, 'g-', label='Training Loss')\n",
        "        val_loss_line, = self.ax.plot(range(1,self.epoch_index+1), self.val_losses, 'r-', label='Validation Loss')\n",
        "        self.ax.legend(handles=[loss_line, val_loss_line])\n",
        "        self.ax.set_ylim((MetricsCallback.GRAPH_MIN, MetricsCallback.GRAPH_MAX))\n",
        "        self.fig.canvas.draw()\n",
        "        if logs['val_loss'] < self.best_val_loss:\n",
        "            self.val_loss_reductions += 1\n",
        "            self.best_val_loss = logs['val_loss']\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            print('\\r    \\r') # to remove the previous line of verbose output of model fit\n",
        "            # time.sleep(0.1)\n",
        "            print('Found lower val loss for epoch {} => {}'.format(self.epoch_index, round(logs['val_loss'], 5)))\n",
        "            if self.val_loss_reductions % MetricsCallback.EPOCHS_BEFORE_VALIDATION == 0:\n",
        "\n",
        "                print('Validation Loss Reduced {} times'.format(self.val_loss_reductions))\n",
        "                print('Evaluating on Validation Data')\n",
        "                Xv_file, yv_file = get_data_files(self.base_load_directory, self.classifications_type, self.level, 'validation') # creates the file paths\n",
        "                Xv, yv = get_data(Xv_file, yv_file, mmap=True) # load the files as ndarray\n",
        "                yvp = self.model.predict_generator(generator=batch_generator(Xv_file, yv_file,\n",
        "                                                   self.batch_size, is_mlp=self.is_mlp, validate=True),\n",
        "                                                   max_q_size=QUEUE_SIZE,\n",
        "                                                   val_samples=yv.shape[1])\n",
        "                yvp_binary = get_binary_0_5(yvp)\n",
        "                print('Generating Validation Metrics')\n",
        "                validation_metrics = get_sequential_metrics(yv, yvp, yvp_binary)\n",
        "                print(\"****** Validation Metrics: Cov Err: {:.3f} | Top 3: {:.3f} | Top 5: {:.3f} | F1 Micro: {:.3f} | F1 Macro: {:.3f}\".format(\n",
        "                    validation_metrics['coverage_error'], validation_metrics['top_3'], validation_metrics['top_5'],\n",
        "                    validation_metrics['f1_micro'], validation_metrics['f1_macro']))\n",
        "                self.metrics_dict[self.epoch_index] = validation_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ErfjXjdb6Is",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# doc2vec sequential helper\n",
        "def get_doc2vec_model(model_path):\n",
        "    return Doc2Vec.load(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bpZWWNIIXqHq",
        "colab": {}
      },
      "source": [
        "# predicting model helper\n",
        "def plot_charts(history):\n",
        "    from matplotlib import pyplot\n",
        "\n",
        "    # plot loss during training\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Loss')\n",
        "    pyplot.plot(history.history['loss'], label='train')\n",
        "    pyplot.plot(history.history['val_loss'], label='test')\n",
        "    pyplot.legend()\n",
        "\n",
        "    # plot accuracy during training\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "    pyplot.legend()\n",
        "    pyplot.show()\n",
        "\n",
        "def get_lstm(optimizer,\n",
        "            init_mode_1, activation_1,\n",
        "            init_mode_2, activation_2,\n",
        "            init_mode_3, activation_3,\n",
        "            init_mode_4, activation_4,\n",
        "            init_mode_5, activation_5,\n",
        "            init_mode_6, activation_6,\n",
        "            weight_constraint_1, \n",
        "            weight_constraint_2, \n",
        "            weight_constraint_3, \n",
        "            weight_constraint_4, \n",
        "            weight_constraint_5, \n",
        "            weight_constraint_6, \n",
        "            dropout_rate_1, \n",
        "            dropout_rate_2, \n",
        "            dropout_rate_3, \n",
        "            dropout_rate_4,\n",
        "            neurons_1, neurons_2, neurons_3,\n",
        "            filters_1, filters_2, filters_3,\n",
        "            kernel_size_1, kernel_size_2, kernel_size_3,\n",
        "            strides_1, strides_2, strides_3,\n",
        "            activation_lstm_1, activation_lstm_2, activation_lstm_3,\n",
        "            recurrent_activation_1, recurrent_activation_2, recurrent_activation_3,\n",
        "            w_dropout_do_1, w_dropout_do_2, w_dropout_do_3, \n",
        "            u_dropout_do_1, u_dropout_do_2, u_dropout_do_3,\n",
        "            backwards_1, backwards_2, backwards_3,\n",
        "            unroll_1, unroll_2, unroll_3,\n",
        "            lstm_output_size_1, lstm_output_size_2, lstm_output_size_3,\n",
        "            input_size, n_classes):\n",
        "    # len_vocabulary, n_classes = 64846, 302\n",
        "    # len_vocabulary, n_classes = 9924, 62\n",
        "    # build up the model\n",
        "\n",
        "    stack_layers = 1\n",
        "\n",
        "    # set up the layers\n",
        "    model = Sequential()\n",
        "    # model.add(keras.layers.Embedding(input_dim=len_vocabulary, output_dim=neurons_1))\n",
        "\n",
        "    # model.add(keras.layers.ZeroPadding1D((1,1), input_shape=(len_vocabulary, neurons_1))) # (sequence_size, len_vocabulary) = X_data.shape[2], X_data.shape[0]\n",
        "    # model.add(keras.layers.Conv1D(filters=filters_1, kernel_size=kernel_size_1, strides=strides_1, activation=activation_1, \n",
        "    #                               kernel_initializer=init_mode_1, kernel_constraint=tf.keras.constraints.max_norm(weight_constraint_1))) \n",
        "    # model.add(keras.layers.MaxPooling1D())\n",
        "\n",
        "    # model.add(keras.layers.ZeroPadding1D((1,1), input_shape=(len_vocabulary, neurons_1)))\n",
        "    # model.add(keras.layers.Conv1D(filters=filters_2, kernel_size=kernel_size_2, strides=strides_2, activation=activation_2, \n",
        "    #                               kernel_initializer=init_mode_2, kernel_constraint=tf.keras.constraints.max_norm(weight_constraint_2)))\n",
        "    # model.add(keras.layers.GlobalMaxPooling1D())\n",
        "\n",
        "    # model.add(keras.layers.ZeroPadding1D((1,1), input_shape=(len_vocabulary, neurons_1)))\n",
        "    # model.add(keras.layers.Conv1D(filters=filters_3, kernel_size=kernel_size_3, strides=strides_3, activation=activation_3, kernel_initializer=init_mode_3, kernel_constraint=max_norm(weight_constraint_3)))\n",
        "    # model.add(keras.layers.GlobalMaxPooling1D())\n",
        "\n",
        "    model.add(LSTM(lstm_output_size_1, activation=activation_lstm_1, recurrent_activation=recurrent_activation_1, use_bias=False,\n",
        "                   input_shape=(1, input_size), \n",
        "                   dropout_W=w_dropout_do_1, dropout_U=u_dropout_do_1,\n",
        "                   implementation=1,\n",
        "                   return_sequences=False if 1 == stack_layers else True,\n",
        "                   go_backwards=backwards_1, stateful=False, unroll=unroll_1))\n",
        "    \n",
        "    # model.add(LSTM(lstm_output_size_2, activation=activation_lstm_2, recurrent_activation=recurrent_activation_2, use_bias=False,\n",
        "    #                input_shape=(1, input_size), \n",
        "    #                dropout_W=w_dropout_do_2, dropout_U=u_dropout_do_2,\n",
        "    #                implementation=1,\n",
        "    #                return_sequences=False if 2 == stack_layers else True,\n",
        "    #                go_backwards=backwards_2, stateful=False, unroll=unroll_2))\n",
        "\n",
        "    # model.add(LSTM(lstm_output_size_3, activation=activation_lstm_3, recurrent_activation=recurrent_activation_3, use_bias=False,\n",
        "    #                input_dim=len_vocabulary, dropout_W=w_dropout_do_3, dropout_U=u_dropout_do_3,\n",
        "    #                implementation=1,\n",
        "    #                return_sequences=False if 3 == stack_layers else True,\n",
        "    #                go_backwards=backwards_3, stateful=False, unroll=unroll_3)\n",
        "\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dropout(dropout_rate_1))\n",
        "    # model.add(Dense(neurons_1, activation=activation_4, kernel_initializer=init_mode_4, \n",
        "    #                 kernel_constraint=tf.keras.constraints.max_norm(weight_constraint_4)))\n",
        "    # model.add(Dropout(dropout_rate_2))\n",
        "    # model.add(Dense(neurons_2, activation=activation_5, kernel_initializer=init_mode_5, \n",
        "    #                 kernel_constraint=tf.keras.constraints.max_norm(weight_constraint_5)))\n",
        "    # model.add(Dropout(dropout_rate_3))\n",
        "    # model.add(Dense(neurons_3, activation=activation_6, kernel_initializer=init_mode_6, \n",
        "    #                 kernel_constraint=tf.keras.constraints.max_norm(weight_constraint_6)))\n",
        "    # model.add(Dropout(dropout_rate_4))\n",
        "    model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "    if optimizer == 'Adam':\n",
        "        optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  # loss='binary_crossentropy', \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy', 'mse'])\n",
        "    return model\n",
        "\n",
        "def run_lstm(model, \n",
        "             train_data, train_labels, test_data, test_labels, val_data, val_labels, \n",
        "             batch_size, callbacks_list, \n",
        "             train_flag,\n",
        "             queue_size = 100,\n",
        "             predicting_batch_size = 64, predicting_steps = None, predicting_max_queue_size = 100, predicting_callbacks_list = None, \n",
        "             epoch = 400):\n",
        "    print('###  LSTM  ###')\n",
        "    # compile the model\n",
        "\n",
        "    if train_flag:\n",
        "        # train the model\n",
        "        history = model.fit_generator(generator=batch_generator(train_data, train_labels, batch_size, queue_size, is_mlp=False, validate=False),\n",
        "                                      validation_data=batch_generator(val_data, val_labels, batch_size, queue_size, is_mlp=False, validate=True),\n",
        "                                      # samples_per_epoch=len(train_data),\n",
        "                                      samples_per_epoch=len(train_data) // batch_size,\n",
        "                                      nb_val_samples=len(val_data),\n",
        "                                      # nb_val_samples=len(val_data) // batch_size,\n",
        "                                      nb_epoch=epoch,\n",
        "                                      callbacks=callbacks_list,\n",
        "                                      max_q_size=queue_size)\n",
        "        # plot_charts(history)\n",
        "        print('finished training')\n",
        "\n",
        "    # using the recorded weights of the best recorded validation loss\n",
        "    # last_model_weights = model.get_weights()\n",
        "    # model.set_weights(metrics_callback.best_weights)\n",
        "\n",
        "    # val_loss, val_acc, val_mse = model.evaluate_generator(generator=batch_generator(val_data, val_labels, predicting_batch_size, predicting_max_queue_size, is_mlp=False, validate=True),\n",
        "    #                                                       max_queue_size=predicting_max_queue_size,\n",
        "    #                                                       steps=len(val_data) // batch_size)\n",
        "\n",
        "    test_loss, test_acc, test_mse = model.evaluate_generator(generator=batch_generator(test_data, test_labels, predicting_batch_size, predicting_max_queue_size, is_mlp=False, validate=True),\n",
        "                                                             max_queue_size=predicting_max_queue_size,\n",
        "                                                             steps=len(test_data) // batch_size)\n",
        "\n",
        "    predictions = model.predict_generator(generator=batch_generator(test_data, test_labels, predicting_batch_size, predicting_max_queue_size, is_mlp=False, validate=True),\n",
        "                                          max_q_size=predicting_max_queue_size,\n",
        "                                          val_samples=len(test_data) // batch_size)\n",
        "    pred_classes = model.predict_classes(test_data, verbose=0)\n",
        "    print(pred_classes)\n",
        "    \n",
        "    print('finished predicting')\n",
        "\n",
        "    # return history, predictions, binary_predictions\n",
        "    # return [test_loss, test_acc, test_mse], predictions, [val_loss, val_acc, val_mse]\n",
        "    return [test_loss, test_acc, test_mse], predictions, pred_classes, [None, None, None]\n",
        "    return [None, None, None], predictions, pred_classes, [None, None, None]\n",
        "\n",
        "def save_sequential_model(model, model_path):\n",
        "    model.save(model_path)\n",
        "    \n",
        "def load_sequential_model(model_path):\n",
        "    return load_model(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LjWxNUVjGj63",
        "colab": {}
      },
      "source": [
        "script_key = \"lstm classify\"\n",
        "\n",
        "GLOBAL_VARS = namedtuple('GLOBAL_VARS', ['MODEL_NAME', 'DOC2VEC_MODEL_NAME', 'DOC2VEC_MODEL', 'NN_MODEL_NAME'])\n",
        "NN_PARAMETER_SEARCH_PREFIX = \"lstm_{}_level_{}_batch_{}_nn_parameter_searches.pkl\"\n",
        "\n",
        "def get_single_df(docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_docvecs):\n",
        "    data_ = np.ndarray((len(docs_list), sequence_size, EMBEDDING_SIZE), dtype=np.float32)\n",
        "    fill_matrix(data_, doc2vec_docvecs, docs_list)\n",
        "    return data_\n",
        "\n",
        "def get_df_data(num_data, training_docs_list, val_docs_list, test_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model_location):\n",
        "    doc2vec_model = get_doc2vec_model(doc2vec_model_location)\n",
        "\n",
        "    if num_data == 2:\n",
        "        X_data = get_single_df(training_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model.docvecs)\n",
        "        Xv_data = get_single_df(val_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model.docvecs)\n",
        "        Xt_data = None\n",
        "    elif num_data == 3:\n",
        "        X_data = get_single_df(training_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model.docvecs)\n",
        "        Xv_data = get_single_df(val_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model.docvecs)\n",
        "        Xt_data = get_single_df(test_docs_list, sequence_size, EMBEDDING_SIZE, doc2vec_model.docvecs)\n",
        "    return X_data, Xv_data, Xt_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WCRiYlb9Zbx0",
        "colab": {}
      },
      "source": [
        "def get_classes_results(testy, yhat_classes, yhat_probs):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    from sklearn.metrics import precision_score\n",
        "    from sklearn.metrics import recall_score\n",
        "    from sklearn.metrics import f1_score\n",
        "    from sklearn.metrics import cohen_kappa_score\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    print(testy.shape)\n",
        "    print(yhat_classes.shape)\n",
        "    print(yhat_probs.shape)\n",
        "    try:\n",
        "        # accuracy: (tp + tn) / (p + n)\n",
        "        accuracy = accuracy_score(testy, yhat_classes)\n",
        "        print('Accuracy: %f' % accuracy)\n",
        "        # precision tp / (tp + fp)\n",
        "        precision = precision_score(testy, yhat_classes)\n",
        "        print('Precision: %f' % precision)\n",
        "        # recall: tp / (tp + fn)\n",
        "        recall = recall_score(testy, yhat_classes)\n",
        "        print('Recall: %f' % recall)\n",
        "        # f1: 2 tp / (2 tp + fp + fn)\n",
        "        f1 = f1_score(testy, yhat_classes)\n",
        "        print('F1 score: %f' % f1)\n",
        "    except:\n",
        "        try:\n",
        "            # kappa\n",
        "            kappa = cohen_kappa_score(testy, yhat_classes)\n",
        "            print('Cohens kappa: %f' % kappa)\n",
        "        except:\n",
        "            try:\n",
        "                # confusion matrix\n",
        "                matrix = confusion_matrix(testy, yhat_classes)\n",
        "                print(matrix)\n",
        "            except:\n",
        "                try:\n",
        "                    # ROC AUC\n",
        "                    auc = roc_auc_score(testy, yhat_probs)\n",
        "                    print('ROC AUC: %f' % auc)\n",
        "                except:\n",
        "                    # accuracy: (tp + tn) / (p + n)\n",
        "                    accuracy = accuracy_score(testy, yhat_probs)\n",
        "                    print('Accuracy: %f' % accuracy)\n",
        "\n",
        "def train_LSTM_from_web(data_frame, text_vectorizer, class_vectorizer, classif_level, classif_type, dataset_location):\n",
        "    print('### LSTM - Training ###')\n",
        "\n",
        "    date = datetime.now().isoformat()\n",
        "    \n",
        "    root_location = get_root_location('data/')\n",
        "    sequential_model_location = link_paths(join_paths(root_location, \"sequential_model/\"), \"sequential_lstm_model \"+date)\n",
        "    output_path = link_paths(join_paths(root_location, \"model_results/\"), \"lstm_results.csv\")\n",
        "    losses_path = link_paths(join_paths(root_location, \"training_losses/\"), \"lstm_losses.csv\")\n",
        "    \n",
        "    save_results = True\n",
        "\n",
        "    model_name = text_vectorizer+'/'+class_vectorizer+'/LSTM'\n",
        "    results = apply_df_vectorizer(data_frame, text_vectorizer, class_vectorizer, model_name)\n",
        "    X_train, X_test, train_labels, test_labels, classes, n_classes, vocab_processor, len_vocabulary = results\n",
        "\n",
        "    X_train, X_val, train_labels, val_labels = get_train_test_from_data(X_train, train_labels)\n",
        "\n",
        "    save_sets(join_paths(root_location, 'model_sets/'), X_train, X_test, X_val, train_labels, test_labels, val_labels, [classes, n_classes, vocab_processor, len_vocabulary])\n",
        "\n",
        "    embedding_size = X_train.shape[1]\n",
        "\n",
        "    if text_vectorizer == 'load_doc2vec':\n",
        "        root_location = get_root_location('data/lstm_outcome/')\n",
        "        doc2vec_vocab_location = link_paths(join_paths(root_location, \"doc2vec_model/vocab_model/\"), \"doc2vec_vocab 2020-01-01\")\n",
        "        output_path = link_paths(join_paths(root_location, 'model_results/'), 'lstm_results.csv')\n",
        "\n",
        "        training_docs_list = X_train['patent_id']\n",
        "        val_docs_list = X_val['patent_id']\n",
        "        test_docs_list = X_test['patent_id']\n",
        "\n",
        "        sequence_size, embedding_size = 1, 200\n",
        "        # train_data, val_data, _ = get_df_data(2, training_docs_list, val_docs_list, None, sequence_size, embedding_size, doc2vec_vocab_location)\n",
        "        train_data, val_data, test_data = get_df_data(3, training_docs_list, val_docs_list, test_docs_list, sequence_size, embedding_size, doc2vec_vocab_location)\n",
        "\n",
        "        vocab_processor = Doc2Vec.load(doc2vec_vocab_location)\n",
        "        len_vocabulary = len(vocab_processor.wv.vocab)\n",
        "\n",
        "    print('train_data: ', train_data[0])\n",
        "    print('dataset shapes: ', train_data.shape, train_labels.shape, val_data.shape, val_labels.shape)\n",
        "    \n",
        "    len_vocabulary = 34736\n",
        "\n",
        "    print(\"output path: \", output_path)\n",
        "    print(\"length vocabulary: \", len_vocabulary, \" number classes: \", n_classes)\n",
        "\n",
        "    # best: {\"batch_size\": 64, \"optimizer\": \"Adam\", \"init_mode_1\": \"uniform\", \"init_mode_2\": \"uniform\", \"init_mode_3\": null, \"init_mode_4\": \"uniform\", \"init_mode_5\": \"uniform\", \"init_mode_6\": \"uniform\", \"activation_1\": \"softmax\", \"activation_2\": \"softmax\", \"activation_3\": null, \"activation_4\": \"softmax\", \"activation_5\": \"softmax\", \"activation_6\": \"softmax\", \"weight_constraint_1\": 3, \"weight_constraint_2\": 3, \"weight_constraint_3\": null, \"weight_constraint_4\": 3, \"weight_constraint_5\": 3, \"weight_constraint_6\": 3, \"dropout_rate_1\": 0.05, \"dropout_rate_2\": 0.1, \"dropout_rate_3\": 0.15, \"dropout_rate_4\": 0.2, \"neurons_1\": 910, \"neurons_2\": 273.0, \"neurons_3\": 182, \"filters_1\": 1, \"filters_2\": 1, \"filters_3\": null, \"kernel_size_1\": 1, \"kernel_size_2\": 1, \"kernel_size_3\": null, \"strides_1\": 1, \"strides_2\": null, \"strides_3\": null, \"activation_lstm_1\": \"softmax\", \"activation_lstm_2\": \"softmax\", \"activation_lstm_3\": \"softmax\", \"recurrent_activation_1\": \"sigmoid\", \"recurrent_activation_2\": \"sigmoid\", \"recurrent_activation_3\": \"sigmoid\", \"w_dropout_do_1\": 0.05, \"w_dropout_do_2\": 0.1, \"w_dropout_do_3\": 0.15, \"u_dropout_do_1\": 0.05, \"u_dropout_do_2\": 0.1, \"u_dropout_do_3\": 0.15, \"backwards_1\": true, \"backwards_2\": true, \"backwards_3\": true, \"unroll_1\": false, \"unroll_2\": false, \"unroll_3\": false, \"lstm_output_size_1\": 273, \"lstm_output_size_2\": null, \"lstm_output_size_3\": null}\n",
        "    parameters = {\"batch_size\": 64,\n",
        "                  \"optimizer\": \"Adam\",\n",
        "                  \"init_mode_1\": \"uniform\",\n",
        "                  \"init_mode_2\": \"uniform\",\n",
        "                  \"init_mode_3\": None,\n",
        "                  \"init_mode_4\": \"uniform\",\n",
        "                  \"init_mode_5\": \"uniform\",\n",
        "                  \"init_mode_6\": \"uniform\",\n",
        "                  \"activation_1\": \"softmax\",\n",
        "                  \"activation_2\": \"softmax\",\n",
        "                  \"activation_3\": None,\n",
        "                  \"activation_4\": \"softmax\",\n",
        "                  \"activation_5\": \"softmax\",\n",
        "                  \"activation_6\": \"softmax\",\n",
        "                  \"weight_constraint_1\": 3,\n",
        "                  \"weight_constraint_2\": 3,\n",
        "                  \"weight_constraint_3\": None,\n",
        "                  \"weight_constraint_4\": 3,\n",
        "                  \"weight_constraint_5\": 3,\n",
        "                  \"weight_constraint_6\": 3,\n",
        "                  # \"dropout_rate_1\": 0.05,\n",
        "                  # \"dropout_rate_2\": 0.1,\n",
        "                  # \"dropout_rate_3\": 0.15,\n",
        "                  # \"dropout_rate_4\": 0.2,\n",
        "                  \"dropout_rate_1\": 0.0,\n",
        "                  \"dropout_rate_2\": 0.0,\n",
        "                  \"dropout_rate_3\": 0.0,\n",
        "                  \"dropout_rate_4\": 0.0,\n",
        "                  \"neurons_1\": 910,\n",
        "                  \"neurons_2\": 273,\n",
        "                  \"neurons_3\": 182,\n",
        "                  \"filters_1\": 1,\n",
        "                  \"filters_2\": 1,\n",
        "                  \"filters_3\": None,\n",
        "                  \"kernel_size_1\": 1,\n",
        "                  \"kernel_size_2\": 1,\n",
        "                  \"kernel_size_3\": None,\n",
        "                  \"strides_1\": 1,\n",
        "                  \"strides_2\": None,\n",
        "                  \"strides_3\": None,\n",
        "                  \"activation_lstm_1\": \"softmax\",\n",
        "                  \"activation_lstm_2\": \"softmax\",\n",
        "                  \"activation_lstm_3\": \"softmax\",\n",
        "                  \"recurrent_activation_1\": \"softmax\",\n",
        "                  \"recurrent_activation_2\": \"softmax\",\n",
        "                  \"recurrent_activation_3\": \"softmax\",\n",
        "                  # \"w_dropout_do_1\": 0.05,\n",
        "                  # \"w_dropout_do_2\": 0.1,\n",
        "                  # \"w_dropout_do_3\": 0.15,\n",
        "                  # \"u_dropout_do_1\": 0.05,\n",
        "                  # \"u_dropout_do_2\": 0.1,\n",
        "                  # \"u_dropout_do_3\": 0.15,\n",
        "                  \"w_dropout_do_1\": 0.05,\n",
        "                  \"w_dropout_do_2\": 0.0,\n",
        "                  \"w_dropout_do_3\": 0.0,\n",
        "                  \"u_dropout_do_1\": 0.05,\n",
        "                  \"u_dropout_do_2\": 0.0,\n",
        "                  \"u_dropout_do_3\": 0.0,\n",
        "                  \"backwards_1\": True,\n",
        "                  \"backwards_2\": True,\n",
        "                  \"backwards_3\": True,\n",
        "                  \"unroll_1\": False,\n",
        "                  \"unroll_2\": False,\n",
        "                  \"unroll_3\": False,\n",
        "                  \"lstm_output_size_1\": 939,\n",
        "                  \"lstm_output_size_2\": 273,\n",
        "                  \"lstm_output_size_3\": None\n",
        "                }\n",
        "\n",
        "    print(\"params: \", parameters)\n",
        "    model = get_lstm(parameters['optimizer'], \n",
        "                    parameters['init_mode_1'], parameters['activation_1'],\n",
        "                    parameters['init_mode_2'], parameters['activation_2'],\n",
        "                    parameters['init_mode_3'], parameters['activation_3'],\n",
        "                    parameters['init_mode_4'], parameters['activation_4'],\n",
        "                    parameters['init_mode_5'], parameters['activation_5'],\n",
        "                    parameters['init_mode_6'], parameters['activation_6'],\n",
        "                    parameters['weight_constraint_1'], \n",
        "                    parameters['weight_constraint_2'], \n",
        "                    parameters['weight_constraint_3'], \n",
        "                    parameters['weight_constraint_4'], \n",
        "                    parameters['weight_constraint_5'], \n",
        "                    parameters['weight_constraint_6'], \n",
        "                    parameters['dropout_rate_1'], \n",
        "                    parameters['dropout_rate_2'], \n",
        "                    parameters['dropout_rate_3'], \n",
        "                    parameters['dropout_rate_4'],\n",
        "                    parameters['neurons_1'], parameters['neurons_2'], parameters['neurons_3'],\n",
        "                    parameters['filters_1'], parameters['filters_2'], parameters['filters_3'],\n",
        "                    parameters['kernel_size_1'], parameters['kernel_size_2'], parameters['kernel_size_3'],\n",
        "                    parameters['strides_1'], parameters['strides_2'], parameters['strides_3'],\n",
        "                    parameters['activation_lstm_1'], parameters['activation_lstm_2'], parameters['activation_lstm_3'],\n",
        "                    parameters['recurrent_activation_1'], parameters['recurrent_activation_2'], parameters['recurrent_activation_3'],\n",
        "                    parameters['w_dropout_do_1'], parameters['w_dropout_do_2'], parameters['w_dropout_do_3'], \n",
        "                    parameters['u_dropout_do_1'], parameters['u_dropout_do_2'], parameters['u_dropout_do_3'],\n",
        "                    parameters['backwards_1'], parameters['backwards_2'], parameters['backwards_3'],\n",
        "                    parameters['unroll_1'], parameters['unroll_2'], parameters['unroll_3'],\n",
        "                    parameters['lstm_output_size_1'], parameters['lstm_output_size_2'], parameters['lstm_output_size_3'],\n",
        "                    embedding_size, n_classes)\n",
        "\n",
        "    print('original: ', val_data.shape)\n",
        "    try:\n",
        "        val_data = val_data[val_data.index <= (val_data.shape[0] // parameters['batch_size']) * parameters['batch_size']]\n",
        "        val_labels = val_labels[val_labels.index <= (val_labels.shape[0] // parameters['batch_size']) * parameters['batch_size']]\n",
        "    except:\n",
        "        val_data = val_data[:((val_data.shape[0] // parameters['batch_size']) * parameters['batch_size'])]\n",
        "        val_labels = val_labels[:((val_labels.shape[0] // parameters['batch_size']) * parameters['batch_size'])]   \n",
        "    print('shirnk: ', val_data.shape)\n",
        "\n",
        "    min_delta, patience = 0.00001, 15\n",
        "    early_stopper = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, verbose=2, mode='auto')\n",
        "    metrics_callback = MetricsCNNCallback(val_data, val_labels, patience)\n",
        "    \n",
        "    # learning rate scheduling\n",
        "    # loss_history = LossHistory(parameters, losses_path)\n",
        "    # # lrate = LearningRateScheduler(exp_decay)\n",
        "    # lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "    metrics, predictions, pred_classes, val_metrics = run_lstm(model, \n",
        "                                                               train_data, train_labels, val_data, val_labels, val_data, val_labels,\n",
        "                                                               parameters['batch_size'], \n",
        "                                                               [early_stopper, metrics_callback],\n",
        "                                                               # [loss_history, lrate, early_stopper, metrics_callback], \n",
        "                                                               True)\n",
        "    save_sequential_model(model, sequential_model_location)\n",
        "    print('model saved')    \n",
        "\n",
        "    binary_predictions = get_binary_0_5(predictions)\n",
        "\n",
        "    print('true values')\n",
        "    print(val_labels)\n",
        "    print(val_labels.shape)\n",
        "    print(val_labels[0])\n",
        "    print('predictions')\n",
        "    print(predictions)\n",
        "    print(predictions.shape)\n",
        "    print(predictions[0])\n",
        "    print('metrics - loss, acc, mse')\n",
        "    print(metrics)\n",
        "    # print('class predictions')\n",
        "    # print(pred_classes)\n",
        "    # print(pred_classes.shape)\n",
        "    # print(pred_classes[0])\n",
        "    print('binary predictions')\n",
        "    print(binary_predictions)\n",
        "    print(binary_predictions.shape)\n",
        "    print(binary_predictions[0])\n",
        "\n",
        "    # get_classes_results(val_labels, pred_classes, predictions)\n",
        "    get_classes_results(val_labels, pred_classes, binary_predictions)\n",
        "    \n",
        "    classifier_name, parameters = get_sequential_classifier_information(model)\n",
        "    model_name = text_vectorizer+'/'+class_vectorizer+'/'+classifier_name\n",
        "    \n",
        "    manual_metrics = calculate_manual_metrics(model_name, val_labels, binary_predictions)\n",
        "    none_average, binary_average, micro_average, macro_average = manual_metrics\n",
        "\n",
        "    validation_metrics = get_sequential_metrics(val_labels, predictions, binary_predictions)\n",
        "    display_sequential_metrics(classifier_name, validation_metrics)\n",
        "    \n",
        "    if save_results:\n",
        "        save_results_function(classifier_name+' Val', validation_metrics, parameters, model_name, classif_level, classif_type, dataset_location)\n",
        "\n",
        "    return model   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FYgrnDBAZfLe",
        "colab": {}
      },
      "source": [
        "def test_LSTM_from_web(model, data_frame, text_vectorizer, class_vectorizer, classif_level, classif_type, dataset_location):\n",
        "    print('### LSTM Doing Testing ###')\n",
        "    date = '01-01-2020'\n",
        "    \n",
        "    root_location = get_root_location('data/')\n",
        "    sequential_model_location = link_paths(join_paths(root_location, \"sequential_model/\"), \"sequential_lstm_model \"+date)\n",
        "    output_path = link_paths(join_paths(root_location, \"model_results/\"), \"lstm_results.csv\")\n",
        "    losses_path = link_paths(join_paths(root_location, \"training_losses/\"), \"lstm_losses.csv\")\n",
        "    \n",
        "    model_name = text_vectorizer+'/'+class_vectorizer+'/lstm'\n",
        "    # results = apply_df_vectorizer(data_frame, text_vectorizer, class_vectorizer, model_name)\n",
        "    # X_data, Xt_data, y_train, y_test, classes, n_classes, vocab_processor, len_vocabulary = results\n",
        "\n",
        "    # X_data, Xv_data, y_train, y_val = get_train_test_from_data(X_data, y_train)\n",
        "\n",
        "    result_path = join_paths(root_location, \"model_results\")\n",
        "\n",
        "    X_data, Xt_data, Xv_data, train_labels, test_labels, val_labels, settings = load_sets(join_paths(root_location, 'model_sets/'))\n",
        "\n",
        "    embedding_size = X_data.shape[1]\n",
        "\n",
        "    if text_vectorizer == 'load_doc2vec':\n",
        "        root_location = get_root_location('data/lstm_outcome/')\n",
        "        doc2vec_vocab_location = link_paths(join_paths(root_location, \"doc2vec_model/vocab_model/\"), \"doc2vec_vocab 2020-01-01\")\n",
        "        result_path = join_paths(root_location, \"model_results\")\n",
        "        output_path = link_paths(join_paths(root_location, \"model_results/\"), \"lstm_results.csv\")\n",
        "        losses_path = link_paths(join_paths(root_location, \"training_losses/\"), \"lstm_losses.csv\")\n",
        "        \n",
        "        training_docs_list = X_data['patent_id']\n",
        "        val_docs_list = Xv_data['patent_id']\n",
        "        test_docs_list = Xt_data['patent_id']\n",
        "\n",
        "        sequence_size, embedding_size = 1, 150\n",
        "        train_data, val_data, test_data = get_df_data(3, training_docs_list, val_docs_list, test_docs_list, sequence_size, embedding_size, doc2vec_vocab_location)\n",
        "\n",
        "        vocab_processor = Doc2Vec.load(doc2vec_vocab_location)\n",
        "        len_vocabulary = len(vocab_processor.wv.vocab)\n",
        "  \n",
        "    save_results = True\n",
        "    \n",
        "    # train_data = train_data.reshape(train_data.shape[0], train_data.shape[2])\n",
        "    # val_data = val_data.reshape(train_data.shape[0], train_data.shape[2])\n",
        "    \n",
        "    parameters = {\"batch_size\": 64}\n",
        "    len_vocabulary = 57335\n",
        "    len_vocabulary = 34736\n",
        "    n_classes = train_labels.shape[1]\n",
        "\n",
        "    print(\"output path: \", output_path)\n",
        "    print(\"length vocabulary: \", len_vocabulary, \" number classes: \", n_classes)\n",
        "    \n",
        "    # model = load_sequential_model(sequential_model_location)\n",
        "\n",
        "    print('original: ', test_data.shape)\n",
        "    try:\n",
        "        test_data = test_data[test_data.index <= (test_data.shape[0] // parameters['batch_size']) * parameters['batch_size']]\n",
        "        test_labels = test_labels[test_labels.index <= (test_labels.shape[0] // parameters['batch_size']) * parameters['batch_size']]\n",
        "    except:\n",
        "        test_data = test_data[:((test_data.shape[0] // parameters['batch_size']) * parameters['batch_size'])]\n",
        "        test_labels = test_labels[:((test_labels.shape[0] // parameters['batch_size']) * parameters['batch_size'])]   \n",
        "    print('shirnk: ', test_data.shape)\n",
        "\n",
        "    metrics, predictions, _, test_metrics = run_lstm(model, \n",
        "                                                     train_data, train_labels, test_data, test_labels, test_data, test_labels,\n",
        "                                                     parameters['batch_size'], None, \n",
        "                                                     False)\n",
        "    binary_predictions = get_binary_0_5(predictions)\n",
        "    \n",
        "    classifier_name, parameters = get_sequential_classifier_information(model)\n",
        "    model_name = text_vectorizer+'/'+class_vectorizer+'/'+classifier_name\n",
        "    \n",
        "    metrics = get_sequential_metrics(test_labels, predictions, binary_predictions)\n",
        "    display_sequential_metrics(classifier_name, metrics)\n",
        "    \n",
        "    if save_results:\n",
        "        save_results_function(classifier_name+' Test', metrics, parameters, model_name, classif_level, classif_type, dataset_location)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIVIXck1GxN1",
        "outputId": "6d7ee41b-fad7-4619-8ec5-29dd6162534b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def shrink_vocabulary(row, vocabulary, data_frame, ids_list):\n",
        "    if isinstance(row, pd.Series):\n",
        "        patent_id, text, classification = row.tolist()\n",
        "\n",
        "        new_tokens = [element for element in text if element in vocabulary]\n",
        "        if new_tokens != [] or len(new_tokens) > 2:\n",
        "            data_frame.loc[data_frame.shape[0]+1] = [patent_id, ' '.join(element for element in new_tokens), classification]\n",
        "        else:\n",
        "            ids_list.append(patent_id)\n",
        "\n",
        "def further_preprocessing_phase(temp_data_frame):\n",
        "    temp_data_frame['text'] = temp_data_frame['text'].apply(lambda text: th.tokenize_text(text) if text != None else '')\n",
        "    # textlist = temp_data_frame['text'].to_numpy()\n",
        "    textlist = temp_data_frame['text'].tolist()\n",
        "\n",
        "    # if it raises an exeption could be the empty texts\n",
        "    patent_dictionary = Dictionary(textlist)\n",
        "    corpus = [patent_dictionary.doc2bow(text) for text in textlist]\n",
        "\n",
        "    print('original dictionary size: ', len(patent_dictionary))\n",
        "\n",
        "    vocab_tf={}\n",
        "    for i in corpus:\n",
        "        for item, count in dict(i).items():\n",
        "            if item in vocab_tf:\n",
        "                vocab_tf[item]+=int(count)\n",
        "            else:\n",
        "                vocab_tf[item] =int(count)\n",
        "\n",
        "    remove_ids=[]\n",
        "    no_of_ids_below_limit=0\n",
        "    for id,count in vocab_tf.items():\n",
        "        if count<=5:\n",
        "            remove_ids.append(id)\n",
        "    patent_dictionary.filter_tokens(bad_ids=remove_ids)\n",
        "\n",
        "    patent_dictionary.filter_extremes(no_below=0)\n",
        "    patent_dictionary.filter_n_most_frequent(30)\n",
        "\n",
        "    print('parsed dictionary size: ', len(patent_dictionary))\n",
        "\n",
        "    vocabulary = list(patent_dictionary.token2id.keys())\n",
        "\n",
        "    ids_list = []\n",
        "    data_frame = pd.DataFrame(columns=['patent_id', 'text', 'classification'])\n",
        "    temp_data_frame.apply(lambda row : shrink_vocabulary(row, vocabulary, data_frame, ids_list), axis=1)\n",
        "    print(len(ids_list))\n",
        "    data_frame.set_index(data_frame['patent_id'], inplace=True)\n",
        "    data_frame.drop(ids_list, axis=0, inplace=True)\n",
        "    return data_frame\n",
        "\n",
        "def shrink_to_sectors(classcode_list):\n",
        "    new_list = []\n",
        "    for class_ in classcode_list:\n",
        "        if class_[0] not in new_list:\n",
        "            new_list.append(class_[0])\n",
        "    return ' '.join(element for element in new_list)\n",
        "\n",
        "def shrink_classes(df, row, class_list):\n",
        "    if isinstance(row, pd.Series):\n",
        "        patent_id, text, class_ = row.tolist()\n",
        "        new_classcodes = []\n",
        "        classcodes = tokenize_text(class_)\n",
        "        for classcode in classcodes:\n",
        "            if not classcode in class_list:\n",
        "                new_classcodes.append(classcode)\n",
        "        if new_classcodes != []:\n",
        "            new_class = ' '.join(el for el in new_classcodes)\n",
        "            df.loc[df.shape[0] + 1] = [patent_id, text, new_class]\n",
        "\n",
        "def reduce_amount_of_classes(data_frame, classification_df):\n",
        "    if isinstance(classification_df, pd.DataFrame):\n",
        "        threshold = int(data_frame.shape[0]/1000*0.35)\n",
        "        if threshold == 0:\n",
        "            threshold = 1\n",
        "        temp_df = classifications_df[classifications_df['count'] <= threshold]\n",
        "        classes_list = temp_df['class'].tolist()\n",
        "    elif isinstance(classification_df, list):\n",
        "        classes_list = classification_df\n",
        "    df = pd.DataFrame(columns=['patent_id', 'text', 'classification'])\n",
        "    data_frame.apply(lambda row : shrink_classes(df, row, classes_list), axis=1)\n",
        "    return df, classes_list\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        if len(sys.argv) == 2:\n",
        "            # source_path = 'test_clean/*/directories - and inside all the patents'\n",
        "            source_path = sys.argv[1]\n",
        "\n",
        "            # here the source_path must be passed as a string of the root directory of all data folders!\n",
        "            source_path, folder_level = handle_partial_args(source_path)\n",
        "        else:\n",
        "            print(usage())\n",
        "            sys.exit(1)\n",
        "    except:\n",
        "        # source_path = ['/Users/elio/Desktop/Patent-Classification/data/test_classification/cleaned/B/']\n",
        "        source_path = ['/Users/elio/Desktop/Patent-Classification/data/test_classification/cleaned/B - 1500 patents/']\n",
        "        source_path = ['/content/drive/My Drive/Colab Notebooks/data/test_classification/cleaned/B - 1500 patents/']\n",
        "    \n",
        "    start = time.time()\n",
        "    print(source_path)\n",
        "    \n",
        "    text_vectorizer = 'load_data/load_doc2vec'\n",
        "    class_vectorizer = 'multi_label'\n",
        "    classif_level = 'description'\n",
        "    classif_type = 'subclasses'\n",
        "\n",
        "    # if there is the '/' into the text_vectorizer, you are supposed to load data from csv\n",
        "    index = text_vectorizer.rfind('/')\n",
        "    if index == -1:\n",
        "        # first option: here you read the directory with the patents\n",
        "        patent_ids, temp_df, classifications_df = load_data(source_path)\n",
        "        data_frame, classif_level, classif_type = get_final_df(patent_ids, temp_df, classif_type)\n",
        "\n",
        "        # data_frame, _ = reduce_amount_of_classes(data_frame, classifications_df)\n",
        "\n",
        "        # save_data_frame(script_key, data_frame, csvfile)\n",
        "    else:\n",
        "        # second option: here you specify the csv\n",
        "        csvfile = 'training_2000_2004_cleaned.csv'\n",
        "        csvfile = 'training_2000_2004_cleaned_test.csv'\n",
        "        csvfile = 'training_2000_2004_cleaned_test_middle.csv'\n",
        "        # save_data_frame(script_key, data_frame, csvfile)\n",
        "        classif_level, classif_type = 'description_claim_abstract_title', 'subclasses'\n",
        "        training_df, train_classifications_df = load_data_frame(script_key, csvfile)\n",
        "        \n",
        "        csvfile = 'testing_2005_cleaned.csv'\n",
        "        csvfile = 'testing_2005_cleaned_test.csv'\n",
        "        csvfile = 'testing_2005_cleaned_test_smaller.csv'\n",
        "        testing_df, classifications_df = load_data_frame(script_key, csvfile)\n",
        "        \n",
        "        # train, classes_to_remove = reduce_amount_of_classes(training_df, train_classifications_df)\n",
        "        # test, _ = reduce_amount_of_classes(testing_df, classes_to_remove)\n",
        "\n",
        "        data_frame = pd.concat([training_df, testing_df])\n",
        "        patent_ids = data_frame['patent_id'].tolist()\n",
        "\n",
        "        text_vectorizer = text_vectorizer[index+1:]\n",
        "\n",
        "    # around 50.000\n",
        "    # data_frame = further_preprocessing_phase(data_frame)\n",
        "\n",
        "    # data_frame['classification'] = data_frame['classification'].apply(lambda classcode : shrink_to_sectors(tokenize_text(classcode)))\n",
        "    # classification_df = pd.DataFrame(columns=['class', 'count'])\n",
        "    # data_frame['classification'].apply(lambda classcode : calculate_class_distribution(classcode, classification_df))\n",
        "    # print('sectors distribution : \\n', classification_df)\n",
        "\n",
        "    print('dataframe shape: ', data_frame.shape)\n",
        "\n",
        "    model = train_LSTM_from_web(data_frame, text_vectorizer, class_vectorizer, classif_level, classif_type, source_path)\n",
        "    \n",
        "    # this would test the model on testing set\n",
        "    # test_LSTM_from_web(model, data_frame, text_vectorizer, class_vectorizer, classif_level, classif_type, source_path)\n",
        "\n",
        "    print(\"end lstm classifition step, execution time: \", time.time()-start)\n",
        "\n",
        "# TODO list:\n",
        "# try all the state-of-the art and maybe we can combine two of them.\n",
        "#\n",
        "# turn on the validation settings\n",
        "#\n",
        "# get_lstm_shapes, try with validation data. change batch size. change testing parameters according to training results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/Colab Notebooks/data/test_classification/cleaned/B - 1500 patents/']\n",
            "dataframe shape:  (6427, 3)\n",
            "ids_list:  []\n",
            "dataframe shape:  (6427, 3)\n",
            "dataframe shape:  (20, 3)\n",
            "ids_list:  []\n",
            "dataframe shape:  (20, 3)\n",
            "dataframe shape:  (6447, 3)\n",
            "### LSTM - Training ###\n",
            "###  multi_label_binarizer  ###\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train_data:  [[-0.14926393  0.07977636 -0.38661826 -0.07619986  0.14820573  0.3177496\n",
            "   0.26178342  0.46967736  0.17745563  0.38124922  0.2027556   0.10479432\n",
            "   0.50334734 -0.04895656 -0.24495538  0.11185762  0.13570793  0.2687881\n",
            "  -0.27668673  0.12726595 -0.4208606   0.08846858 -0.45114213  0.25289002\n",
            "   0.30377838  0.17314757  0.2933514  -0.15407667  0.05223534 -0.15608248\n",
            "   0.41895208  0.34857622  0.10931011  0.10909563  0.07831977 -0.03037874\n",
            "   0.19191973  0.28977036 -0.2738388   0.45971164  0.24957372  0.16481625\n",
            "  -0.16774483 -0.55281603 -0.36570773  0.02722728  0.15667216 -0.10197079\n",
            "   0.03612706 -0.17816657 -0.33224815 -0.07364052 -0.09939025  0.02899808\n",
            "   0.23298644 -0.26179814  0.12099829 -0.06969366 -0.2682944   0.18446282\n",
            "  -0.27763772 -0.37492537 -0.06047355 -0.17538446  0.06546511  0.06101125\n",
            "  -0.1253456  -0.48712656 -0.06078298 -0.14184383  0.32122707 -0.11701781\n",
            "  -0.3812059  -0.24231191 -0.38690302 -0.0822603  -0.58484185  0.3014285\n",
            "  -0.26212066 -0.05576542 -0.53141755 -0.48406535 -0.327381    0.10429033\n",
            "   0.10839402 -0.2849448   0.24187526 -0.21190754  0.03675113  0.27594227\n",
            "  -0.06389396  0.10236987  0.00305313  0.01781236  0.47550237 -0.5452388\n",
            "   0.00867378  0.06279072  0.07338108  0.48224032  0.18933947 -0.40241182\n",
            "  -0.53482217  0.6129779  -0.11898848 -0.0551234  -0.40667617  0.03714795\n",
            "  -0.09339457  0.35155514 -0.01294528  0.1444879   0.08806864  0.17537427\n",
            "   0.39794883 -0.12765642  0.19236195  0.18406583  0.10307404 -0.04292064\n",
            "   0.10652125 -0.5573594   0.2418661  -0.38557455  0.49070206 -0.178393\n",
            "  -0.31964225 -0.14364491 -0.5142378   0.01436066  0.08053431 -0.284194\n",
            "  -0.07446154  0.38300163 -0.06206707  0.24117616  0.13119864 -0.1311603\n",
            "  -0.10108577 -0.18223004  0.14597547  0.18448077  0.33721304 -0.33402464\n",
            "   0.27233633  0.19085051 -0.4845171   0.51687044  0.24151343 -0.13712671\n",
            "  -0.1324691   0.10188343  0.12080149 -0.3543714  -0.14652069  0.16294508\n",
            "   0.25018346  0.13476309 -0.08179006 -0.47301394  0.40163434 -0.11955377\n",
            "  -0.19460551 -0.0922143  -0.28407755 -0.4194539  -0.27720645  0.16819368\n",
            "  -0.17746924  1.1160625  -0.05163168 -0.18703973 -0.28344724  0.36373702\n",
            "   0.15452926 -0.17938687 -0.3284517  -0.49884132  0.05894485 -0.09259918\n",
            "  -0.14163749  0.16987911  0.06621092  0.09114122  0.36830416  0.19524235\n",
            "  -0.23951957 -0.05231889 -0.00129459 -0.27663022 -0.1473685  -0.7760546\n",
            "   0.3130396   0.65306485 -0.3827094  -0.2408516   0.0298087  -0.251405\n",
            "   0.0155381  -0.10029703]]\n",
            "dataset shapes:  (4125, 1, 200) (4125, 8) (1032, 1, 200) (1032, 8)\n",
            "output path:  /content/drive/My Drive/Colab Notebooks/data/lstm_outcome/model_results/lstm_results.csv\n",
            "length vocabulary:  34736  number classes:  8\n",
            "params:  {'batch_size': 64, 'optimizer': 'Adam', 'init_mode_1': 'uniform', 'init_mode_2': 'uniform', 'init_mode_3': None, 'init_mode_4': 'uniform', 'init_mode_5': 'uniform', 'init_mode_6': 'uniform', 'activation_1': 'softmax', 'activation_2': 'softmax', 'activation_3': None, 'activation_4': 'softmax', 'activation_5': 'softmax', 'activation_6': 'softmax', 'weight_constraint_1': 3, 'weight_constraint_2': 3, 'weight_constraint_3': None, 'weight_constraint_4': 3, 'weight_constraint_5': 3, 'weight_constraint_6': 3, 'dropout_rate_1': 0.0, 'dropout_rate_2': 0.0, 'dropout_rate_3': 0.0, 'dropout_rate_4': 0.0, 'neurons_1': 910, 'neurons_2': 273, 'neurons_3': 182, 'filters_1': 1, 'filters_2': 1, 'filters_3': None, 'kernel_size_1': 1, 'kernel_size_2': 1, 'kernel_size_3': None, 'strides_1': 1, 'strides_2': None, 'strides_3': None, 'activation_lstm_1': 'softmax', 'activation_lstm_2': 'softmax', 'activation_lstm_3': 'softmax', 'recurrent_activation_1': 'softmax', 'recurrent_activation_2': 'softmax', 'recurrent_activation_3': 'softmax', 'w_dropout_do_1': 0.05, 'w_dropout_do_2': 0.0, 'w_dropout_do_3': 0.0, 'u_dropout_do_1': 0.05, 'u_dropout_do_2': 0.0, 'u_dropout_do_3': 0.0, 'backwards_1': True, 'backwards_2': True, 'backwards_3': True, 'unroll_1': False, 'unroll_2': False, 'unroll_3': False, 'lstm_output_size_1': 939, 'lstm_output_size_2': 273, 'lstm_output_size_3': None}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(939, activation=\"softmax\", recurrent_activation=\"softmax\", use_bias=False, input_shape=(1, 200), implementation=1, return_sequences=False, go_backwards=True, stateful=False, unroll=False, dropout=0.05, recurrent_dropout=0.05)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 939)               4278084   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 7520      \n",
            "=================================================================\n",
            "Total params: 4,285,604\n",
            "Trainable params: 4,285,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "original:  (1032, 1, 200)\n",
            "shirnk:  (1024, 1, 200)\n",
            "###  LSTM  ###\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:133: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(generator=<generator..., validation_data=<generator..., callbacks=[<keras.ca..., steps_per_epoch=64, epochs=400, validation_steps=1024, max_queue_size=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 495ms/step - loss: 2.4013 - acc: 0.2577 - mean_squared_error: 0.1268 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 11/400\n",
            " 3/64 [>.............................] - ETA: 10s - loss: 2.4266 - acc: 0.2708 - mean_squared_error: 0.1279\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3941 - acc: 0.2571 - mean_squared_error: 0.1266\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 499ms/step - loss: 2.3919 - acc: 0.2570 - mean_squared_error: 0.1265 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 12/400\n",
            " 4/64 [>.............................] - ETA: 9s - loss: 2.4335 - acc: 0.2656 - mean_squared_error: 0.1281 \n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3866 - acc: 0.2571 - mean_squared_error: 0.1264\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 511ms/step - loss: 2.3879 - acc: 0.2570 - mean_squared_error: 0.1265 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 13/400\n",
            " 5/64 [=>............................] - ETA: 9s - loss: 2.3910 - acc: 0.2625 - mean_squared_error: 0.1265 \n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3788 - acc: 0.2571 - mean_squared_error: 0.1262\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 517ms/step - loss: 2.3779 - acc: 0.2570 - mean_squared_error: 0.1262 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 14/400\n",
            " 6/64 [=>............................] - ETA: 9s - loss: 2.3991 - acc: 0.2604 - mean_squared_error: 0.1268\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3764 - acc: 0.2571 - mean_squared_error: 0.1262\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 508ms/step - loss: 2.3745 - acc: 0.2570 - mean_squared_error: 0.1261 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 15/400\n",
            " 7/64 [==>...........................] - ETA: 9s - loss: 2.3828 - acc: 0.2589 - mean_squared_error: 0.1263 \n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3678 - acc: 0.2581 - mean_squared_error: 0.1259\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 507ms/step - loss: 2.3705 - acc: 0.2570 - mean_squared_error: 0.1260 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 16/400\n",
            " 8/64 [==>...........................] - ETA: 9s - loss: 2.3625 - acc: 0.2578 - mean_squared_error: 0.1256\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3635 - acc: 0.2571 - mean_squared_error: 0.1258\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 508ms/step - loss: 2.3617 - acc: 0.2580 - mean_squared_error: 0.1257 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 17/400\n",
            " 9/64 [===>..........................] - ETA: 9s - loss: 2.3781 - acc: 0.2500 - mean_squared_error: 0.1264\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3627 - acc: 0.2564 - mean_squared_error: 0.1258\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 509ms/step - loss: 2.3623 - acc: 0.2560 - mean_squared_error: 0.1258 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 18/400\n",
            "10/64 [===>..........................] - ETA: 8s - loss: 2.3614 - acc: 0.2562 - mean_squared_error: 0.1257\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3593 - acc: 0.2554 - mean_squared_error: 0.1257\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 503ms/step - loss: 2.3574 - acc: 0.2572 - mean_squared_error: 0.1256 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 19/400\n",
            "11/64 [====>.........................] - ETA: 8s - loss: 2.3566 - acc: 0.2543 - mean_squared_error: 0.1255\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3610 - acc: 0.2554 - mean_squared_error: 0.1258\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 502ms/step - loss: 2.3560 - acc: 0.2550 - mean_squared_error: 0.1256 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 20/400\n",
            "12/64 [====>.........................] - ETA: 8s - loss: 2.3439 - acc: 0.2643 - mean_squared_error: 0.1251\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3553 - acc: 0.2574 - mean_squared_error: 0.1256\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 510ms/step - loss: 2.3563 - acc: 0.2572 - mean_squared_error: 0.1257 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 21/400\n",
            "13/64 [=====>........................] - ETA: 8s - loss: 2.3182 - acc: 0.2620 - mean_squared_error: 0.1240\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3474 - acc: 0.2559 - mean_squared_error: 0.1253\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 501ms/step - loss: 2.3480 - acc: 0.2570 - mean_squared_error: 0.1254 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 22/400\n",
            "14/64 [=====>........................] - ETA: 8s - loss: 2.3234 - acc: 0.2612 - mean_squared_error: 0.1242\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3458 - acc: 0.2561 - mean_squared_error: 0.1253\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 503ms/step - loss: 2.3463 - acc: 0.2558 - mean_squared_error: 0.1253 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 23/400\n",
            "15/64 [======>.......................] - ETA: 7s - loss: 2.3257 - acc: 0.2656 - mean_squared_error: 0.1244\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3442 - acc: 0.2586 - mean_squared_error: 0.1252\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 497ms/step - loss: 2.3446 - acc: 0.2572 - mean_squared_error: 0.1253 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 24/400\n",
            "16/64 [======>.......................] - ETA: 7s - loss: 2.3273 - acc: 0.2637 - mean_squared_error: 0.1246\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3454 - acc: 0.2581 - mean_squared_error: 0.1253\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 31s 488ms/step - loss: 2.3430 - acc: 0.2582 - mean_squared_error: 0.1252 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 25/400\n",
            "17/64 [======>.......................] - ETA: 7s - loss: 2.3281 - acc: 0.2583 - mean_squared_error: 0.1246\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3452 - acc: 0.2571 - mean_squared_error: 0.1254\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 2.3442 - acc: 0.2567 - mean_squared_error: 0.1253 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 26/400\n",
            "18/64 [=======>......................] - ETA: 7s - loss: 2.3193 - acc: 0.2587 - mean_squared_error: 0.1243\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3412 - acc: 0.2561 - mean_squared_error: 0.1252\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 500ms/step - loss: 2.3415 - acc: 0.2572 - mean_squared_error: 0.1252 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 27/400\n",
            "19/64 [=======>......................] - ETA: 7s - loss: 2.3159 - acc: 0.2574 - mean_squared_error: 0.1241\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3425 - acc: 0.2561 - mean_squared_error: 0.1253\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 494ms/step - loss: 2.3389 - acc: 0.2558 - mean_squared_error: 0.1251 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 28/400\n",
            "20/64 [========>.....................] - ETA: 7s - loss: 2.3170 - acc: 0.2609 - mean_squared_error: 0.1242\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3406 - acc: 0.2554 - mean_squared_error: 0.1252\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 31s 492ms/step - loss: 2.3417 - acc: 0.2572 - mean_squared_error: 0.1253 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 29/400\n",
            "21/64 [========>.....................] - ETA: 6s - loss: 2.3063 - acc: 0.2597 - mean_squared_error: 0.1238\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3343 - acc: 0.2536 - mean_squared_error: 0.1250\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 2.3361 - acc: 0.2550 - mean_squared_error: 0.1251 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 30/400\n",
            "22/64 [=========>....................] - ETA: 6s - loss: 2.3100 - acc: 0.2649 - mean_squared_error: 0.1239\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3353 - acc: 0.2556 - mean_squared_error: 0.1250\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 512ms/step - loss: 2.3345 - acc: 0.2555 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 31/400\n",
            "23/64 [=========>....................] - ETA: 8s - loss: 2.3153 - acc: 0.2683 - mean_squared_error: 0.1241\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3371 - acc: 0.2569 - mean_squared_error: 0.1251\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 508ms/step - loss: 2.3363 - acc: 0.2570 - mean_squared_error: 0.1251 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 32/400\n",
            "24/64 [==========>...................] - ETA: 6s - loss: 2.3132 - acc: 0.2676 - mean_squared_error: 0.1241\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3331 - acc: 0.2564 - mean_squared_error: 0.1250\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 505ms/step - loss: 2.3354 - acc: 0.2567 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 33/400\n",
            "25/64 [==========>...................] - ETA: 6s - loss: 2.3116 - acc: 0.2675 - mean_squared_error: 0.1240\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3300 - acc: 0.2556 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 2.3318 - acc: 0.2565 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 34/400\n",
            "26/64 [===========>..................] - ETA: 6s - loss: 2.3176 - acc: 0.2680 - mean_squared_error: 0.1242\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3326 - acc: 0.2571 - mean_squared_error: 0.1249\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 505ms/step - loss: 2.3317 - acc: 0.2560 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 35/400\n",
            "27/64 [===========>..................] - ETA: 6s - loss: 2.3218 - acc: 0.2697 - mean_squared_error: 0.1244\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3297 - acc: 0.2571 - mean_squared_error: 0.1249\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 503ms/step - loss: 2.3338 - acc: 0.2580 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 36/400\n",
            "28/64 [============>.................] - ETA: 5s - loss: 2.3199 - acc: 0.2667 - mean_squared_error: 0.1243\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3281 - acc: 0.2551 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 499ms/step - loss: 2.3284 - acc: 0.2560 - mean_squared_error: 0.1248 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 37/400\n",
            "29/64 [============>.................] - ETA: 5s - loss: 2.3288 - acc: 0.2683 - mean_squared_error: 0.1247\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3350 - acc: 0.2564 - mean_squared_error: 0.1251\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 506ms/step - loss: 2.3317 - acc: 0.2560 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 38/400\n",
            "30/64 [=============>................] - ETA: 5s - loss: 2.3292 - acc: 0.2698 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3363 - acc: 0.2574 - mean_squared_error: 0.1251\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 508ms/step - loss: 2.3349 - acc: 0.2572 - mean_squared_error: 0.1251 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 39/400\n",
            "31/64 [=============>................] - ETA: 5s - loss: 2.3223 - acc: 0.2686 - mean_squared_error: 0.1245\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3333 - acc: 0.2571 - mean_squared_error: 0.1250\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 515ms/step - loss: 2.3326 - acc: 0.2570 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 40/400\n",
            "32/64 [==============>...............] - ETA: 5s - loss: 2.3197 - acc: 0.2681 - mean_squared_error: 0.1244\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3298 - acc: 0.2564 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 513ms/step - loss: 2.3316 - acc: 0.2570 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 41/400\n",
            "33/64 [==============>...............] - ETA: 5s - loss: 2.3185 - acc: 0.2675 - mean_squared_error: 0.1243\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3241 - acc: 0.2569 - mean_squared_error: 0.1246\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 518ms/step - loss: 2.3288 - acc: 0.2563 - mean_squared_error: 0.1248 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 42/400\n",
            "34/64 [==============>...............] - ETA: 5s - loss: 2.3222 - acc: 0.2684 - mean_squared_error: 0.1245\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3282 - acc: 0.2574 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 517ms/step - loss: 2.3258 - acc: 0.2575 - mean_squared_error: 0.1247 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 43/400\n",
            "35/64 [===============>..............] - ETA: 4s - loss: 2.3306 - acc: 0.2670 - mean_squared_error: 0.1249\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3337 - acc: 0.2554 - mean_squared_error: 0.1251\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 522ms/step - loss: 2.3326 - acc: 0.2567 - mean_squared_error: 0.1250 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 44/400\n",
            "36/64 [===============>..............] - ETA: 4s - loss: 2.3262 - acc: 0.2669 - mean_squared_error: 0.1247\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3281 - acc: 0.2571 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 517ms/step - loss: 2.3311 - acc: 0.2555 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 45/400\n",
            "37/64 [================>.............] - ETA: 4s - loss: 2.3243 - acc: 0.2690 - mean_squared_error: 0.1246\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3247 - acc: 0.2593 - mean_squared_error: 0.1246\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 513ms/step - loss: 2.3268 - acc: 0.2585 - mean_squared_error: 0.1247 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 46/400\n",
            "38/64 [================>.............] - ETA: 4s - loss: 2.3294 - acc: 0.2660 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3305 - acc: 0.2579 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 518ms/step - loss: 2.3276 - acc: 0.2577 - mean_squared_error: 0.1248 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 47/400\n",
            "39/64 [=================>............] - ETA: 4s - loss: 2.3326 - acc: 0.2644 - mean_squared_error: 0.1250\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3316 - acc: 0.2581 - mean_squared_error: 0.1249\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 512ms/step - loss: 2.3324 - acc: 0.2570 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 48/400\n",
            "40/64 [=================>............] - ETA: 4s - loss: 2.3277 - acc: 0.2641 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3293 - acc: 0.2576 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 32s 508ms/step - loss: 2.3285 - acc: 0.2580 - mean_squared_error: 0.1248 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 49/400\n",
            "41/64 [==================>...........] - ETA: 3s - loss: 2.3290 - acc: 0.2622 - mean_squared_error: 0.1249\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3287 - acc: 0.2554 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 34s 525ms/step - loss: 2.3300 - acc: 0.2565 - mean_squared_error: 0.1249 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 50/400\n",
            "42/64 [==================>...........] - ETA: 3s - loss: 2.3278 - acc: 0.2626 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "63/64 [============================>.] - ETA: 0s - loss: 2.3296 - acc: 0.2556 - mean_squared_error: 0.1248\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "64/64 [==============================] - 33s 510ms/step - loss: 2.3278 - acc: 0.2558 - mean_squared_error: 0.1248 - val_loss: nan - val_acc: nan - val_mean_squared_error: nan\n",
            "Epoch 00050: early stopping\n",
            "finished training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: UserWarning: Update your `predict_generator` call to the Keras 2 API: `predict_generator(generator=<generator..., steps=16, max_queue_size=100)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "\n",
            "in new epoch for X_data, y_train with validation data\n",
            "[0 0 0 ... 0 0 0]\n",
            "finished predicting\n",
            "model saved\n",
            "true values\n",
            "[[0 0 0 ... 0 0 1]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " ...\n",
            " [0 0 0 ... 0 1 1]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 1 ... 0 0 0]]\n",
            "(1024, 8)\n",
            "[0 0 0 0 0 0 0 1]\n",
            "predictions\n",
            "[[0.20440532 0.15428013 0.17565835 ... 0.06381655 0.1840171  0.17374788]\n",
            " [0.20439747 0.1542844  0.17565727 ... 0.0638271  0.18400748 0.17373586]\n",
            " [0.20440297 0.15428138 0.17565814 ... 0.06381963 0.1840143  0.17374435]\n",
            " ...\n",
            " [0.20440532 0.15428011 0.17565835 ... 0.06381654 0.1840171  0.1737479 ]\n",
            " [0.20434582 0.15431245 0.17564994 ... 0.06389729 0.1839437  0.17365596]\n",
            " [0.20440532 0.15428011 0.17565835 ... 0.06381654 0.18401712 0.1737479 ]]\n",
            "(1024, 8)\n",
            "[0.20440532 0.15428013 0.17565835 0.02067725 0.02339742 0.06381655\n",
            " 0.1840171  0.17374788]\n",
            "binary predictions\n",
            "[[1 1 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 1 1]\n",
            " ...\n",
            " [1 1 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 1 1]\n",
            " [1 1 1 ... 0 1 1]]\n",
            "(1024, 8)\n",
            "[1 1 1 0 0 0 1 1]\n",
            "(1024, 8)\n",
            "(1024,)\n",
            "(1024, 8)\n",
            "ROC AUC: 0.500000\n",
            "//////// \n",
            "true_values:\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 1]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 1 0]\n",
            " [1 0 1 ... 1 0 0]]\n",
            "(8, 1024)\n",
            "//////// \n",
            "predictions:\n",
            "[[1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 1 1 ... 1 1 1]\n",
            " [1 1 1 ... 1 1 1]]\n",
            "(8, 1024)\n",
            "0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1,   1024\n",
            "0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1,   2048\n",
            "0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1,   3072\n",
            "0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0,   4096\n",
            "0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0,   5120\n",
            "0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 1 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 1 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0, 0 0,   6144\n",
            "0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1,   7168\n",
            "1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 1 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 0 1, 1 1, 1 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 1 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1, 0 1, 1 1, 0 1, 0 1,   8192\n",
            "\n",
            "global - true positives :  1160 true negatives :  2933 false positives :  3960 false negatives :  139\n",
            "per class - precision values to average:  [0.2529296875, 0.1875, 0.2490234375, 0, 0, 0, 0.2177734375, 0.2255859375]\n",
            "per class - recall values to average:  [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
            "test accuracy : 0.49963\n",
            "micro test precision : 0.22656,  macro test precision : 0.14160\n",
            "micro test recall : 0.89299,  macro test recall : 0.62500\n",
            "micro test f1_score : 0.36143,  macro test f1_score : 0.23089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "###  calculating_metrics  ###\n",
            "@@@  Sequential  @@@\n",
            "Over all labels - Coverage error: 3.578, Average labels: 1.270\n",
            "Percentage - Top 1: 0.270, Top 3: 0.567, Top 5: 0.893\n",
            "Macro - precision: 0.142, recall: 0.625, f1: 0.231\n",
            "Micro - precision: 0.227, recall: 0.893, f1: 0.361\n",
            "###  saving_results  ###\n",
            "end lstm classifition step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}